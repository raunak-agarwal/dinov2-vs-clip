{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import glob\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Dictionaries for multi-label classification:\n",
    "\n",
    "COVID: 0 for negative, 1 for positive\n",
    "\n",
    "CheXechonet: 0 for negative, 1 for positive\n",
    "\n",
    "TBX11K: 0 for healthy, 1 for sick, 2 for tb\n",
    "\n",
    "RSNA: 0 for normal, 1 for not normal & no lung opacity, 2 for lung opacity\n",
    "\n",
    "SIIM: 0 for negative, 1 for positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chexbert_labels      df_chexpert_plus_240401.csv  radgraph-XL-annotations.zip\n",
      "chexbert_labels.zip  radgraph-XL-annotations\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/CheXpert\\ Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive.zip\t\t\t     df_chexpert_plus_240401.csv\n",
      "chexpert_5x200.csv\t\t     final-datasets\n",
      "chexpert_plus_labels_with_5x200.csv  README.md\n",
      "chexpert_processed.csv\t\t     train_cheXbert.xls\n",
      "CheXpert-v1.0-small\t\t     train_visualCheXbert.xls\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/CheXpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223462, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>split</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient42142/study5/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy tube remains in pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient42142/study8/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy and subdiaphragmati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient42142/study2/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.single portable semiupright ap v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient42142/study4/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1. patchy subsegmental bibasilar (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient42142/study3/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.upright frontal view of the ches...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path_to_image   age     sex   race  split  \\\n",
       "0  train/patient42142/study5/view1_frontal.jpg  62.0  Female  White  train   \n",
       "1  train/patient42142/study8/view1_frontal.jpg  62.0  Female  White  train   \n",
       "2  train/patient42142/study2/view1_frontal.jpg  62.0  Female  White  train   \n",
       "3  train/patient42142/study4/view1_frontal.jpg  62.0  Female  White  train   \n",
       "4  train/patient42142/study3/view1_frontal.jpg  62.0  Female  White  train   \n",
       "\n",
       "                                              report  \n",
       "0  impression: 1.tracheostomy tube remains in pla...  \n",
       "1  impression: 1.tracheostomy and subdiaphragmati...  \n",
       "2  impression: 1.single portable semiupright ap v...  \n",
       "3  impression: 1. patchy subsegmental bibasilar (...  \n",
       "4  impression: 1.upright frontal view of the ches...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_plus = \"../data/CheXpert Plus/df_chexpert_plus_240401.csv\"\n",
    "chexpert_plus = pd.read_csv(chexpert_plus)\n",
    "print(chexpert_plus.shape)\n",
    "\n",
    "def get_report_from_row(row):\n",
    "    def replace_nan(t):\n",
    "        return \"\" if pd.isna(t) else t\n",
    "    \n",
    "    section_impression = replace_nan(row['section_impression'])\n",
    "    section_findings = replace_nan(row['section_findings'])\n",
    "    section_summary = replace_nan(row['section_summary'])\n",
    "    section_report = replace_nan(row['report'])    \n",
    "    \n",
    "    if section_impression and section_findings and section_summary:\n",
    "        text = f\"IMPRESSION: {section_impression}\\nFINDINGS: {section_findings}\\nSUMMARY: {section_summary}\"\n",
    "    elif section_impression and section_findings:\n",
    "        text = f\"IMPRESSION: {section_impression}\\nFINDINGS: {section_findings}\"\n",
    "    elif section_impression:\n",
    "        text = f\"IMPRESSION: {section_impression}\"\n",
    "    elif section_findings:\n",
    "        text = f\"FINDINGS: {section_findings}\"\n",
    "    elif section_report:\n",
    "        text = f\"REPORT: {section_report}\"\n",
    "    else:\n",
    "        text = \"\"\n",
    "        \n",
    "    text = \" \".join(text.split()).strip().lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "#keep the following columns: path_to_image age sex race split report\n",
    "\n",
    "chexpert_plus['report'] = chexpert_plus.apply(get_report_from_row, axis=1)\n",
    "chexpert_plus = chexpert_plus[['path_to_image', 'age', 'sex', 'race', 'split', 'report']]\n",
    "chexpert_plus.head()\n",
    "\n",
    "\n",
    "chexpert_plus.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223462, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient42142/study5/view1_frontal.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient42142/study8/view1_frontal.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient42142/study2/view1_frontal.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient42142/study4/view1_frontal.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient42142/study3/view1_frontal.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path_to_image  Enlarged Cardiomediastinum  \\\n",
       "0  train/patient42142/study5/view1_frontal.jpg                         0.0   \n",
       "1  train/patient42142/study8/view1_frontal.jpg                         0.0   \n",
       "2  train/patient42142/study2/view1_frontal.jpg                         0.0   \n",
       "3  train/patient42142/study4/view1_frontal.jpg                         0.0   \n",
       "4  train/patient42142/study3/view1_frontal.jpg                         0.0   \n",
       "\n",
       "   Cardiomegaly  Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  \\\n",
       "0           0.0           0.0          0.0    0.0            0.0        0.0   \n",
       "1           0.0           0.0          0.0    0.0            0.0        0.0   \n",
       "2           0.0           1.0          0.0    0.0            0.0        0.0   \n",
       "3           0.0           0.0          0.0    0.0            1.0        0.0   \n",
       "4           0.0           0.0          0.0    0.0            0.0        0.0   \n",
       "\n",
       "   Atelectasis  Pneumothorax  Pleural Effusion  Pleural Other  Fracture  \\\n",
       "0          0.0           0.0               0.0            0.0       0.0   \n",
       "1          1.0           0.0               0.0            0.0       0.0   \n",
       "2          1.0           0.0               1.0            0.0       0.0   \n",
       "3          1.0           0.0               0.0            0.0       0.0   \n",
       "4          1.0           0.0               0.0            0.0       0.0   \n",
       "\n",
       "   Support Devices  No Finding  \n",
       "0              1.0         0.0  \n",
       "1              1.0         0.0  \n",
       "2              1.0         0.0  \n",
       "3              1.0         0.0  \n",
       "4              1.0         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load labels for chexpert plus\n",
    "chexpert_plus_labels = \"../data/CheXpert Plus/chexbert_labels/report_fixed.json\"\n",
    "chexpert_plus_labels = pd.read_json(chexpert_plus_labels, lines=True)\n",
    "chexpert_plus_labels.iloc[:, 1:] = chexpert_plus_labels.iloc[:, 1:].fillna(0) # Replace nan with 0 in columns 1 onwards\n",
    "chexpert_plus_labels.iloc[:, 1:] = chexpert_plus_labels.iloc[:, 1:].replace(-1.0, 1.0) # Replace -1.0 with 1.0\n",
    "print(chexpert_plus_labels.shape)\n",
    "chexpert_plus_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path_to_image', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
       "       'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
       "       'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',\n",
       "       'Fracture', 'Support Devices', 'No Finding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_plus_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223414, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient00001/study1/view1_frontal.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient00002/study2/view1_frontal.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>87</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient00002/study1/view1_frontal.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient00002/study1/view2_lateral.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient00003/study1/view1_frontal.jpg</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Path     Sex  Age Frontal/Lateral  \\\n",
       "0  train/patient00001/study1/view1_frontal.jpg  Female   68         Frontal   \n",
       "1  train/patient00002/study2/view1_frontal.jpg  Female   87         Frontal   \n",
       "2  train/patient00002/study1/view1_frontal.jpg  Female   83         Frontal   \n",
       "3  train/patient00002/study1/view2_lateral.jpg  Female   83         Lateral   \n",
       "4  train/patient00003/study1/view1_frontal.jpg    Male   41         Frontal   \n",
       "\n",
       "  AP/PA  Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "0    AP                         0.0           0.0           0.0          0.0   \n",
       "1    AP                         0.0           1.0           1.0          0.0   \n",
       "2    AP                         0.0           0.0           1.0          0.0   \n",
       "3   NaN                         0.0           0.0           1.0          0.0   \n",
       "4    AP                         0.0           0.0           0.0          0.0   \n",
       "\n",
       "   Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0    0.0            0.0        0.0          0.0           0.0   \n",
       "1    1.0            1.0        0.0          1.0           0.0   \n",
       "2    0.0            1.0        0.0          0.0           0.0   \n",
       "3    0.0            1.0        0.0          0.0           0.0   \n",
       "4    1.0            0.0        0.0          0.0           0.0   \n",
       "\n",
       "   Pleural Effusion  Pleural Other  Fracture  Support Devices  No Finding  \n",
       "0               0.0            0.0       0.0              1.0         1.0  \n",
       "1               1.0            0.0       1.0              0.0         0.0  \n",
       "2               0.0            0.0       1.0              0.0         0.0  \n",
       "3               0.0            0.0       1.0              0.0         0.0  \n",
       "4               0.0            0.0       0.0              0.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_original = \"../data/CheXpert/train_cheXbert.xls\"\n",
    "chexpert_original = pd.read_csv(chexpert_original)\n",
    "chexpert_original.iloc[:, 5:] = chexpert_original.iloc[:, 5:].fillna(0) # Replace NaNs from columns 5 onwards with 0\n",
    "chexpert_original.iloc[:, 5:] = chexpert_original.iloc[:, 5:].replace(-1.0, 1.0) # Replace -1.0 with 1.0\n",
    "# Replace CheXpert-v1.0 with empty string\n",
    "chexpert_original['Path'] = chexpert_original['Path'].apply(lambda x: x.replace(\"CheXpert-v1.0/\", \"\"))\n",
    "print(chexpert_original.shape)\n",
    "chexpert_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223228, 6)\n",
      "(223414, 19)\n"
     ]
    }
   ],
   "source": [
    "# Check if there is any row in path_to_image column that has the word \"train\"\n",
    "print(chexpert_plus[chexpert_plus['path_to_image'].str.contains('train')].shape)\n",
    "print(chexpert_original[chexpert_original['Path'].str.contains('train')].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223228, 6)\n",
      "(223228, 19)\n"
     ]
    }
   ],
   "source": [
    "# check for overlap in path_to_image column and Path column\n",
    "print(chexpert_plus[chexpert_plus['path_to_image'].isin(chexpert_original['Path'])].shape)\n",
    "print(chexpert_original[chexpert_original['Path'].isin(chexpert_plus['path_to_image'])].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223462 223414 223228\n",
      "\n",
      "Label Distribution Comparison:\n",
      "Label                          CheXpert Plus             Original CheXpert        \n",
      "--------------------------------------------------------------------------------\n",
      "Enlarged Cardiomediastinum     28468.0 (12.74%)          22664.0 (10.14%)         \n",
      "Cardiomegaly                   43195.0 (19.33%)          34483.0 (15.43%)         \n",
      "Lung Opacity                   111130.0 (49.73%)         103407.0 (46.28%)        \n",
      "Lung Lesion                    14510.0 (6.49%)           10919.0 (4.89%)          \n",
      "Edema                          67287.0 (30.11%)          65269.0 (29.21%)         \n",
      "Consolidation                  42810.0 (19.16%)          40371.0 (18.07%)         \n",
      "Pneumonia                      29008.0 (12.98%)          24242.0 (10.85%)         \n",
      "Atelectasis                    73550.0 (32.91%)          68278.0 (30.56%)         \n",
      "Pneumothorax                   22014.0 (9.85%)           20304.0 (9.09%)          \n",
      "Pleural Effusion               101548.0 (45.44%)         96948.0 (43.39%)         \n",
      "Pleural Other                  8731.0 (3.91%)            6690.0 (2.99%)           \n",
      "Fracture                       11693.0 (5.23%)           9203.0 (4.12%)           \n",
      "Support Devices                133316.0 (59.66%)         113190.0 (50.66%)        \n",
      "No Finding                     13053.0 (5.84%)           21124.0 (9.46%)          \n",
      "\n",
      "Label Comparison Statistics:\n",
      "                            matching  different     total  match_percentage\n",
      "Pleural Other               208311.0    14917.0  223228.0         93.317595\n",
      "Fracture                    203352.0    19876.0  223228.0         91.096099\n",
      "Lung Lesion                 199134.0    24094.0  223228.0         89.206551\n",
      "No Finding                  191936.0    31292.0  223228.0         85.982045\n",
      "Pneumothorax                185270.0    37958.0  223228.0         82.995861\n",
      "Enlarged Cardiomediastinum  178002.0    45226.0  223228.0         79.739997\n",
      "Pneumonia                   176314.0    46914.0  223228.0         78.983819\n",
      "Cardiomegaly                159093.0    64135.0  223228.0         71.269285\n",
      "Consolidation               155661.0    67567.0  223228.0         69.731844\n",
      "Edema                       130491.0    92737.0  223228.0         58.456376\n",
      "Atelectasis                 126683.0    96545.0  223228.0         56.750497\n",
      "Pleural Effusion            116281.0   106947.0  223228.0         52.090688\n",
      "Support Devices             116179.0   107049.0  223228.0         52.044994\n",
      "Lung Opacity                113206.0   110022.0  223228.0         50.713172\n",
      "\n",
      "Overall match percentage: 72.31%\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the common labels between datasets\n",
    "chexpert_labels = [\n",
    "    'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', \n",
    "    'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
    "    'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',\n",
    "    'Fracture', 'Support Devices', 'No Finding'\n",
    "]\n",
    "\n",
    "# Create a comparison dictionary to store statistics\n",
    "comparison_stats = defaultdict(lambda: {'matching': 0, 'different': 0, 'total': 0})\n",
    "\n",
    "# Get overlapping image paths\n",
    "common_paths = set(chexpert_plus_labels['path_to_image']).intersection(\n",
    "    set(chexpert_original['Path'])\n",
    ")\n",
    "\n",
    "print(len(chexpert_plus_labels), len(chexpert_original), len(common_paths))\n",
    "\n",
    "# Print label distributions side by side\n",
    "print(\"\\nLabel Distribution Comparison:\")\n",
    "print(f\"{'Label':<30} {'CheXpert Plus':<25} {'Original CheXpert':<25}\")\n",
    "print(\"-\" * 80)\n",
    "for label in chexpert_labels:\n",
    "    plus_count = chexpert_plus_labels[label].sum()\n",
    "    plus_total = len(chexpert_plus_labels)\n",
    "    plus_pct = f\"{plus_count} ({(plus_count/plus_total*100):.2f}%)\"\n",
    "    \n",
    "    orig_count = chexpert_original[label].sum() \n",
    "    orig_total = len(chexpert_original)\n",
    "    orig_pct = f\"{orig_count} ({(orig_count/orig_total*100):.2f}%)\"\n",
    "    \n",
    "    print(f\"{label:<30} {plus_pct:<25} {orig_pct:<25}\")\n",
    "\n",
    "# Vectorized comparison for each label\n",
    "for label in chexpert_labels:\n",
    "    # Create mapping series for fast lookup\n",
    "    plus_labels = pd.Series(\n",
    "        chexpert_plus_labels[label].values,\n",
    "        index=chexpert_plus_labels['path_to_image']\n",
    "    )\n",
    "    orig_labels = pd.Series(\n",
    "        chexpert_original[label].values,\n",
    "        index=chexpert_original['Path']\n",
    "    )\n",
    "    \n",
    "    # Get labels for common paths\n",
    "    plus_common = plus_labels[list(common_paths)]\n",
    "    orig_common = orig_labels[list(common_paths)]\n",
    "    \n",
    "    # Compare labels\n",
    "    matching = (plus_common == orig_common).sum()\n",
    "    total = len(common_paths)\n",
    "    different = total - matching\n",
    "    \n",
    "    comparison_stats[label] = {\n",
    "        'matching': matching,\n",
    "        'different': different,\n",
    "        'total': total,\n",
    "        'match_percentage': (matching/total * 100) if total > 0 else 0\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "comparison_df = pd.DataFrame(comparison_stats).T\n",
    "print(\"\\nLabel Comparison Statistics:\")\n",
    "print(comparison_df.sort_values('match_percentage', ascending=False))\n",
    "\n",
    "# Print overall statistics\n",
    "total_comparisons = sum(stats['total'] for stats in comparison_stats.values())\n",
    "total_matching = sum(stats['matching'] for stats in comparison_stats.values())\n",
    "print(f\"\\nOverall match percentage: {(total_matching/total_comparisons * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223462, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>split</th>\n",
       "      <th>report</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient42142/study5/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy tube remains in pla...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient42142/study8/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy and subdiaphragmati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient42142/study2/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.single portable semiupright ap v...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient42142/study4/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1. patchy subsegmental bibasilar (...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient42142/study3/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.upright frontal view of the ches...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path_to_image   age     sex   race  split  \\\n",
       "0  train/patient42142/study5/view1_frontal.jpg  62.0  Female  White  train   \n",
       "1  train/patient42142/study8/view1_frontal.jpg  62.0  Female  White  train   \n",
       "2  train/patient42142/study2/view1_frontal.jpg  62.0  Female  White  train   \n",
       "3  train/patient42142/study4/view1_frontal.jpg  62.0  Female  White  train   \n",
       "4  train/patient42142/study3/view1_frontal.jpg  62.0  Female  White  train   \n",
       "\n",
       "                                              report  \\\n",
       "0  impression: 1.tracheostomy tube remains in pla...   \n",
       "1  impression: 1.tracheostomy and subdiaphragmati...   \n",
       "2  impression: 1.single portable semiupright ap v...   \n",
       "3  impression: 1. patchy subsegmental bibasilar (...   \n",
       "4  impression: 1.upright frontal view of the ches...   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  Edema  \\\n",
       "0                         0.0           0.0           0.0          0.0    0.0   \n",
       "1                         0.0           0.0           0.0          0.0    0.0   \n",
       "2                         0.0           0.0           1.0          0.0    0.0   \n",
       "3                         0.0           0.0           0.0          0.0    0.0   \n",
       "4                         0.0           0.0           0.0          0.0    0.0   \n",
       "\n",
       "   Consolidation  Pneumonia  Atelectasis  Pneumothorax  Pleural Effusion  \\\n",
       "0            0.0        0.0          0.0           0.0               0.0   \n",
       "1            0.0        0.0          1.0           0.0               0.0   \n",
       "2            0.0        0.0          1.0           0.0               1.0   \n",
       "3            1.0        0.0          1.0           0.0               0.0   \n",
       "4            0.0        0.0          1.0           0.0               0.0   \n",
       "\n",
       "   Pleural Other  Fracture  Support Devices  No Finding  \n",
       "0            0.0       0.0              1.0         0.0  \n",
       "1            0.0       0.0              1.0         0.0  \n",
       "2            0.0       0.0              1.0         0.0  \n",
       "3            0.0       0.0              1.0         0.0  \n",
       "4            0.0       0.0              1.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map chexpert_plus to chexpert_plus_labels\n",
    "chexpert_plus = chexpert_plus.merge(chexpert_plus_labels, on='path_to_image')\n",
    "print(chexpert_plus.shape)\n",
    "chexpert_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>Report Impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient38614/study1/view1_frontal.jpg</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n1. bilateral apices of the lungs are obscure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient53625/study1/view1_frontal.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n1.   ap supine chest radiograph.   there has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient37669/study1/view1_frontal.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n \\n1.ap chest radiograph taken in recovery h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient15715/study1/view1_frontal.jpg</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n \\n1.  mild right mid and lower lung atelect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient48702/study1/view1_frontal.jpg</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\n \\n1.low lung volumes with presumed right b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Path     Sex  Age Frontal/Lateral  \\\n",
       "0  train/patient38614/study1/view1_frontal.jpg    Male   26         Frontal   \n",
       "1  train/patient53625/study1/view1_frontal.jpg  Female   46         Frontal   \n",
       "2  train/patient37669/study1/view1_frontal.jpg  Female   60         Frontal   \n",
       "3  train/patient15715/study1/view1_frontal.jpg    Male   41         Frontal   \n",
       "4  train/patient48702/study1/view1_frontal.jpg    Male   49         Frontal   \n",
       "\n",
       "  AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  \\\n",
       "0    AP         0.0                         0.0           0.0           0.0   \n",
       "1    AP         0.0                         0.0           0.0           0.0   \n",
       "2    AP         0.0                         0.0           0.0           0.0   \n",
       "3    PA         0.0                         0.0           0.0           0.0   \n",
       "4    AP         0.0                         0.0           0.0           0.0   \n",
       "\n",
       "   Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0          0.0    0.0            0.0        0.0          1.0           0.0   \n",
       "1          0.0    0.0            0.0        0.0          1.0           0.0   \n",
       "2          0.0    0.0            0.0        0.0          1.0           0.0   \n",
       "3          0.0    0.0            0.0        0.0          1.0           0.0   \n",
       "4          0.0    0.0            0.0        0.0          1.0           0.0   \n",
       "\n",
       "   Pleural Effusion  Pleural Other  Fracture  Support Devices  \\\n",
       "0               0.0            0.0       0.0              0.0   \n",
       "1               0.0            0.0       0.0              0.0   \n",
       "2               0.0            0.0       0.0              0.0   \n",
       "3               0.0            0.0       0.0              0.0   \n",
       "4               0.0            0.0       0.0              0.0   \n",
       "\n",
       "                                   Report Impression  \n",
       "0  \\n1. bilateral apices of the lungs are obscure...  \n",
       "1  \\n1.   ap supine chest radiograph.   there has...  \n",
       "2  \\n \\n1.ap chest radiograph taken in recovery h...  \n",
       "3  \\n \\n1.  mild right mid and lower lung atelect...  \n",
       "4   \\n \\n1.low lung volumes with presumed right b...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_5x200 = \"../data/CheXpert/chexpert_5x200.csv\"\n",
    "chexpert_5x200 = pd.read_csv(chexpert_5x200)\n",
    "chexpert_5x200.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "print(chexpert_5x200.shape)\n",
    "chexpert_5x200['Path'] = chexpert_5x200['Path'].apply(lambda x: x.replace(\"CheXpert-v1.0/\", \"\"))\n",
    "chexpert_5x200_paths = set(chexpert_5x200['Path'].to_list())\n",
    "chexpert_5x200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the rows in chexpert_5x200 that are present in chexpert_plus. then replace the \"split\" column in chexpert_plus with \"test\" for those rows\n",
    "# x = chexpert_5x200[chexpert_5x200['Path'].isin(chexpert_plus['path_to_image'])]\n",
    "# chexpert_plus.loc[chexpert_plus['path_to_image'].isin(x['Path']), 'split'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222464, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    222230\n",
       "valid       234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rows in chexpert_plus that are present in chexpert_5x200 (chexpert_5x200_paths)\n",
    "chexpert_plus = chexpert_plus[~chexpert_plus['path_to_image'].isin(chexpert_5x200_paths)]\n",
    "print(chexpert_plus.shape)\n",
    "chexpert_plus.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    222230\n",
       "test       1000\n",
       "valid       234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the image paths in chexpert_5x200 are present in chexpert_plus \n",
    "\n",
    "x = chexpert_5x200[~chexpert_5x200['Path'].isin(chexpert_plus['path_to_image'])]\n",
    "x.drop(columns=[\"Frontal/Lateral\", \"AP/PA\"], inplace=True)\n",
    "x['race'] = \"Unknown\"\n",
    "x['split'] = \"test\"\n",
    "x.rename(columns={'Path': 'path_to_image', 'Report Impression': 'report', 'Age': 'age', 'Sex': 'sex'}, inplace=True)\n",
    "#copy x into chexpert_plus. first format it according to the format of chexpert_plus and then append it to chexpert_plus\n",
    "chexpert_plus = pd.concat([chexpert_plus, x])\n",
    "chexpert_plus.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223464, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>split</th>\n",
       "      <th>report</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient42142/study5/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy tube remains in pla...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient42142/study8/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy and subdiaphragmati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient42142/study2/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.single portable semiupright ap v...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient42142/study4/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1. patchy subsegmental bibasilar (...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient42142/study3/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.upright frontal view of the ches...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 path_to_image   age     sex   race  split  \\\n",
       "0  train/patient42142/study5/view1_frontal.jpg  62.0  Female  White  train   \n",
       "1  train/patient42142/study8/view1_frontal.jpg  62.0  Female  White  train   \n",
       "2  train/patient42142/study2/view1_frontal.jpg  62.0  Female  White  train   \n",
       "3  train/patient42142/study4/view1_frontal.jpg  62.0  Female  White  train   \n",
       "4  train/patient42142/study3/view1_frontal.jpg  62.0  Female  White  train   \n",
       "\n",
       "                                              report  \\\n",
       "0  impression: 1.tracheostomy tube remains in pla...   \n",
       "1  impression: 1.tracheostomy and subdiaphragmati...   \n",
       "2  impression: 1.single portable semiupright ap v...   \n",
       "3  impression: 1. patchy subsegmental bibasilar (...   \n",
       "4  impression: 1.upright frontal view of the ches...   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  Edema  \\\n",
       "0                         0.0           0.0           0.0          0.0    0.0   \n",
       "1                         0.0           0.0           0.0          0.0    0.0   \n",
       "2                         0.0           0.0           1.0          0.0    0.0   \n",
       "3                         0.0           0.0           0.0          0.0    0.0   \n",
       "4                         0.0           0.0           0.0          0.0    0.0   \n",
       "\n",
       "   Consolidation  Pneumonia  Atelectasis  Pneumothorax  Pleural Effusion  \\\n",
       "0            0.0        0.0          0.0           0.0               0.0   \n",
       "1            0.0        0.0          1.0           0.0               0.0   \n",
       "2            0.0        0.0          1.0           0.0               1.0   \n",
       "3            1.0        0.0          1.0           0.0               0.0   \n",
       "4            0.0        0.0          1.0           0.0               0.0   \n",
       "\n",
       "   Pleural Other  Fracture  Support Devices  No Finding  \n",
       "0            0.0       0.0              1.0         0.0  \n",
       "1            0.0       0.0              1.0         0.0  \n",
       "2            0.0       0.0              1.0         0.0  \n",
       "3            0.0       0.0              1.0         0.0  \n",
       "4            0.0       0.0              1.0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chexpert_plus.to_csv(\"../data/CheXpert/chexpert_plus_labels_with_5x200.csv\", index=False, header=True, sep=\"\\t\")\n",
    "chexpert_plus = pd.read_csv(\"../data/CheXpert/CheXpert-v1.0-small/chexpert_plus_labels_with_5x200.csv\", sep=\"\\t\")\n",
    "print(chexpert_plus.shape)\n",
    "chexpert_plus.split.value_counts()\n",
    "chexpert_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cardiomegaly        200.0\n",
       "Edema               200.0\n",
       "Consolidation       200.0\n",
       "Atelectasis         200.0\n",
       "Pleural Effusion    200.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_plus[chexpert_plus['split'] == 'test'][['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis','Pleural Effusion']].sum()\n",
    "# chexpert_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223648\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../data/CheXpert/CheXpert-v1.0-small/*/*/*/*.jpg\")\n",
    "images = [name.replace(\"../data/CheXpert/CheXpert-v1.0-small/\", \"\") for name in images]\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "s1 = set(chexpert_5x200['Path'].to_list())\n",
    "s2 = set(chexpert_plus['path_to_image'].to_list())\n",
    "s3 = set(images)\n",
    "s4 = set(chexpert_plus[chexpert_plus['split'] == 'test']['path_to_image'].to_list())\n",
    "print(len(s1.intersection(s2)))\n",
    "print(len(s1.intersection(s3)))\n",
    "print(len(s1.intersection(s4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Path', 'Sex', 'Age', 'Frontal/Lateral', 'AP/PA', 'No Finding',\n",
      "       'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity',\n",
      "       'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis',\n",
      "       'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture',\n",
      "       'Support Devices', 'Report Impression'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cardiomegaly  Edema  Consolidation  Atelectasis  Pleural Effusion\n",
       "297           1.0    0.0            0.0          0.0               0.0\n",
       "103           0.0    0.0            0.0          1.0               0.0\n",
       "822           0.0    0.0            0.0          0.0               1.0\n",
       "288           1.0    0.0            0.0          0.0               0.0\n",
       "58            0.0    0.0            0.0          1.0               0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chexpert_5x200.columns)\n",
    "chexpert_5x200[['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis','Pleural Effusion']].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cardiomegaly        200.0\n",
       "Edema               200.0\n",
       "Consolidation       200.0\n",
       "Atelectasis         200.0\n",
       "Pleural Effusion    200.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_5x200[['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis','Pleural Effusion']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>path_to_dcm</th>\n",
       "      <th>frontal_lateral</th>\n",
       "      <th>ap_pa</th>\n",
       "      <th>deid_patient_id</th>\n",
       "      <th>patient_report_date_order</th>\n",
       "      <th>report</th>\n",
       "      <th>section_narrative</th>\n",
       "      <th>section_clinical_history</th>\n",
       "      <th>section_history</th>\n",
       "      <th>...</th>\n",
       "      <th>section_accession_number</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>interpreter_needed</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>recent_bmi</th>\n",
       "      <th>deceased</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>train/patient12349/study17/view2_frontal.jpg</td>\n",
       "      <td>train/patient12349/study17/view2_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient12349</td>\n",
       "      <td>21</td>\n",
       "      <td>NARRATIVE:\\nRADIOGRAPHIC EXAMINATION OF THE CH...</td>\n",
       "      <td>\\nRADIOGRAPHIC EXAMINATION OF THE CHEST: 1/13/...</td>\n",
       "      <td>57 years of age, Female, rule out infiltrate....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n18918811\\nThis report has been anonymized. A...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>No</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>31.9</td>\n",
       "      <td>No</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>train/patient26886/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient26886/study1/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>patient26886</td>\n",
       "      <td>2</td>\n",
       "      <td>NARRATIVE:\\nCHEST:  Two views.  1/11/2007\\nCLI...</td>\n",
       "      <td>\\nCHEST:  Two views.  1/11/2007\\n</td>\n",
       "      <td>48 -year-old male with hepatocellular carcino...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n#2-4-0-7-9-0-6-5-3-4-7-7\\nThis report has be...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>No</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>31.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>train/patient25525/study9/view1_frontal.jpg</td>\n",
       "      <td>train/patient25525/study9/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient25525</td>\n",
       "      <td>12</td>\n",
       "      <td>NARRATIVE:\\nExam: Chest 1 View, 11/22/2001\\n \\...</td>\n",
       "      <td>\\nExam: Chest 1 View, 11/22/2001\\n \\n</td>\n",
       "      <td>42 years old Female with Post bronchoscopy\\n \\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n36817447047\\nThis report has been anonymized...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>13.6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>train/patient08963/study10/view2_frontal.jpg</td>\n",
       "      <td>train/patient08963/study10/view2_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient08963</td>\n",
       "      <td>16</td>\n",
       "      <td>NARRATIVE:\\nPORTABLE CHEST: 12/24/2010 1713 ho...</td>\n",
       "      <td>\\nPORTABLE CHEST: 12/24/2010 1713 hours\\n</td>\n",
       "      <td>66 -year-old male status post- heart transpla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n#017367\\nThis report has been anonymized. Al...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>train/patient08963/study10/view1_frontal.jpg</td>\n",
       "      <td>train/patient08963/study10/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient08963</td>\n",
       "      <td>17</td>\n",
       "      <td>NARRATIVE:\\nPORTABLE CHEST: 3/29/2008 1713 hou...</td>\n",
       "      <td>\\nPORTABLE CHEST: 3/29/2008 1713 hours\\n</td>\n",
       "      <td>66 -year-old male status post- heart transpla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n0_3_2_1_0_9_9_8\\nThis report has been anonym...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222803</th>\n",
       "      <td>train/patient18399/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient18399/study1/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient18399</td>\n",
       "      <td>1</td>\n",
       "      <td>NARRATIVE:\\nChest 1 View 5-14-2010\\n \\nCLINICA...</td>\n",
       "      <td>\\nChest 1 View 5-14-2010\\n \\n</td>\n",
       "      <td>73 years-old Male. Cp \\n \\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n63789586172\\nThis report has been anonymized...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "      <td>No</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>26.4</td>\n",
       "      <td>No</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222907</th>\n",
       "      <td>train/patient09787/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient09787/study1/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient09787</td>\n",
       "      <td>1</td>\n",
       "      <td>NARRATIVE:\\nCHEST, ONE VIEW:   1-18-2011\\n \\n ...</td>\n",
       "      <td>\\nCHEST, ONE VIEW:   1-18-2011\\n \\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nCJRSQXYBX0\\nThis report has been anonymized....</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>22.7</td>\n",
       "      <td>No</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223010</th>\n",
       "      <td>train/patient52455/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient52455/study1/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient52455</td>\n",
       "      <td>1</td>\n",
       "      <td>NARRATIVE:\\nSINGLE VIEW PORTABLE CHEST: 3/26/0...</td>\n",
       "      <td>\\nSINGLE VIEW PORTABLE CHEST: 3/26/08 AT 0955 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n#uhwplxbxoul\\nThis report has been anonymize...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223457</th>\n",
       "      <td>train/patient59696/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient59696/study1/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient59696</td>\n",
       "      <td>1</td>\n",
       "      <td>NARRATIVE:\\nRADIOGRAPHIC EXAMINATION OF THE CH...</td>\n",
       "      <td>\\nRADIOGRAPHIC EXAMINATION OF THE CHEST: 12/31...</td>\n",
       "      <td>80 years of age, Female, Pulmonary edema.\\n \\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n#7n4778536837\\nThis report has been anonymiz...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "      <td>No</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>24.0</td>\n",
       "      <td>No</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223461</th>\n",
       "      <td>train/patient48017/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient48017/study1/view1_frontal.dcm</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>patient48017</td>\n",
       "      <td>1</td>\n",
       "      <td>NARRATIVE:\\nCOMPARISON: 6/4/2015\\n \\nIMPRESSIO...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n5851643010\\nThis report has been anonymized....</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic/Non-Latino</td>\n",
       "      <td>No</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>36.4</td>\n",
       "      <td>No</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       path_to_image  \\\n",
       "236     train/patient12349/study17/view2_frontal.jpg   \n",
       "317      train/patient26886/study1/view1_frontal.jpg   \n",
       "1118     train/patient25525/study9/view1_frontal.jpg   \n",
       "1140    train/patient08963/study10/view2_frontal.jpg   \n",
       "1141    train/patient08963/study10/view1_frontal.jpg   \n",
       "...                                              ...   \n",
       "222803   train/patient18399/study1/view1_frontal.jpg   \n",
       "222907   train/patient09787/study1/view1_frontal.jpg   \n",
       "223010   train/patient52455/study1/view1_frontal.jpg   \n",
       "223457   train/patient59696/study1/view1_frontal.jpg   \n",
       "223461   train/patient48017/study1/view1_frontal.jpg   \n",
       "\n",
       "                                         path_to_dcm frontal_lateral ap_pa  \\\n",
       "236     train/patient12349/study17/view2_frontal.dcm         Frontal    AP   \n",
       "317      train/patient26886/study1/view1_frontal.dcm         Frontal    PA   \n",
       "1118     train/patient25525/study9/view1_frontal.dcm         Frontal    AP   \n",
       "1140    train/patient08963/study10/view2_frontal.dcm         Frontal    AP   \n",
       "1141    train/patient08963/study10/view1_frontal.dcm         Frontal    AP   \n",
       "...                                              ...             ...   ...   \n",
       "222803   train/patient18399/study1/view1_frontal.dcm         Frontal    AP   \n",
       "222907   train/patient09787/study1/view1_frontal.dcm         Frontal    AP   \n",
       "223010   train/patient52455/study1/view1_frontal.dcm         Frontal    AP   \n",
       "223457   train/patient59696/study1/view1_frontal.dcm         Frontal    AP   \n",
       "223461   train/patient48017/study1/view1_frontal.dcm         Frontal    AP   \n",
       "\n",
       "       deid_patient_id  patient_report_date_order  \\\n",
       "236       patient12349                         21   \n",
       "317       patient26886                          2   \n",
       "1118      patient25525                         12   \n",
       "1140      patient08963                         16   \n",
       "1141      patient08963                         17   \n",
       "...                ...                        ...   \n",
       "222803    patient18399                          1   \n",
       "222907    patient09787                          1   \n",
       "223010    patient52455                          1   \n",
       "223457    patient59696                          1   \n",
       "223461    patient48017                          1   \n",
       "\n",
       "                                                   report  \\\n",
       "236     NARRATIVE:\\nRADIOGRAPHIC EXAMINATION OF THE CH...   \n",
       "317     NARRATIVE:\\nCHEST:  Two views.  1/11/2007\\nCLI...   \n",
       "1118    NARRATIVE:\\nExam: Chest 1 View, 11/22/2001\\n \\...   \n",
       "1140    NARRATIVE:\\nPORTABLE CHEST: 12/24/2010 1713 ho...   \n",
       "1141    NARRATIVE:\\nPORTABLE CHEST: 3/29/2008 1713 hou...   \n",
       "...                                                   ...   \n",
       "222803  NARRATIVE:\\nChest 1 View 5-14-2010\\n \\nCLINICA...   \n",
       "222907  NARRATIVE:\\nCHEST, ONE VIEW:   1-18-2011\\n \\n ...   \n",
       "223010  NARRATIVE:\\nSINGLE VIEW PORTABLE CHEST: 3/26/0...   \n",
       "223457  NARRATIVE:\\nRADIOGRAPHIC EXAMINATION OF THE CH...   \n",
       "223461  NARRATIVE:\\nCOMPARISON: 6/4/2015\\n \\nIMPRESSIO...   \n",
       "\n",
       "                                        section_narrative  \\\n",
       "236     \\nRADIOGRAPHIC EXAMINATION OF THE CHEST: 1/13/...   \n",
       "317                     \\nCHEST:  Two views.  1/11/2007\\n   \n",
       "1118                \\nExam: Chest 1 View, 11/22/2001\\n \\n   \n",
       "1140            \\nPORTABLE CHEST: 12/24/2010 1713 hours\\n   \n",
       "1141             \\nPORTABLE CHEST: 3/29/2008 1713 hours\\n   \n",
       "...                                                   ...   \n",
       "222803                      \\nChest 1 View 5-14-2010\\n \\n   \n",
       "222907               \\nCHEST, ONE VIEW:   1-18-2011\\n \\n    \n",
       "223010  \\nSINGLE VIEW PORTABLE CHEST: 3/26/08 AT 0955 ...   \n",
       "223457  \\nRADIOGRAPHIC EXAMINATION OF THE CHEST: 12/31...   \n",
       "223461                                                 \\n   \n",
       "\n",
       "                                 section_clinical_history section_history  \\\n",
       "236      57 years of age, Female, rule out infiltrate....             NaN   \n",
       "317      48 -year-old male with hepatocellular carcino...             NaN   \n",
       "1118      42 years old Female with Post bronchoscopy\\n \\n             NaN   \n",
       "1140     66 -year-old male status post- heart transpla...             NaN   \n",
       "1141     66 -year-old male status post- heart transpla...             NaN   \n",
       "...                                                   ...             ...   \n",
       "222803                        73 years-old Male. Cp \\n \\n             NaN   \n",
       "222907                                                NaN             NaN   \n",
       "223010                                                NaN             NaN   \n",
       "223457     80 years of age, Female, Pulmonary edema.\\n \\n             NaN   \n",
       "223461                                                NaN             NaN   \n",
       "\n",
       "        ...                           section_accession_number   age     sex  \\\n",
       "236     ...  \\n18918811\\nThis report has been anonymized. A...  58.0  Female   \n",
       "317     ...  \\n#2-4-0-7-9-0-6-5-3-4-7-7\\nThis report has be...  49.0    Male   \n",
       "1118    ...  \\n36817447047\\nThis report has been anonymized...  40.0  Female   \n",
       "1140    ...  \\n#017367\\nThis report has been anonymized. Al...  66.0    Male   \n",
       "1141    ...  \\n0_3_2_1_0_9_9_8\\nThis report has been anonym...  66.0    Male   \n",
       "...     ...                                                ...   ...     ...   \n",
       "222803  ...  \\n63789586172\\nThis report has been anonymized...  74.0    Male   \n",
       "222907  ...  \\nCJRSQXYBX0\\nThis report has been anonymized....  69.0  Female   \n",
       "223010  ...  \\n#uhwplxbxoul\\nThis report has been anonymize...  22.0    Male   \n",
       "223457  ...  \\n#7n4778536837\\nThis report has been anonymiz...  81.0  Female   \n",
       "223461  ...  \\n5851643010\\nThis report has been anonymized....  82.0  Female   \n",
       "\n",
       "           race                ethnicity interpreter_needed insurance_type  \\\n",
       "236       Other          Hispanic/Latino                 No       Medicare   \n",
       "317       White          Hispanic/Latino                 No        Unknown   \n",
       "1118      Other          Hispanic/Latino                Yes       Medicare   \n",
       "1140    Unknown                  Unknown            Unknown        Unknown   \n",
       "1141    Unknown                  Unknown            Unknown        Unknown   \n",
       "...         ...                      ...                ...            ...   \n",
       "222803    White  Non-Hispanic/Non-Latino                 No       Medicare   \n",
       "222907    Asian  Non-Hispanic/Non-Latino                Yes       Medicare   \n",
       "223010  Unknown                  Unknown            Unknown       Medicare   \n",
       "223457    White  Non-Hispanic/Non-Latino                 No       Medicare   \n",
       "223461    White  Non-Hispanic/Non-Latino                 No       Medicare   \n",
       "\n",
       "       recent_bmi  deceased  split  \n",
       "236          31.9        No  train  \n",
       "317          31.8       Yes  train  \n",
       "1118         13.6       Yes  train  \n",
       "1140          NaN       Yes  train  \n",
       "1141          NaN       Yes  train  \n",
       "...           ...       ...    ...  \n",
       "222803       26.4        No  train  \n",
       "222907       22.7        No  train  \n",
       "223010        NaN        No  train  \n",
       "223457       24.0        No  train  \n",
       "223461       36.4        No  train  \n",
       "\n",
       "[998 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert_5x200[chexpert_5x200['Path'].isin(chexpert_plus['path_to_image'])]\n",
    "\n",
    "# Inverse of the above\n",
    "chexpert_plus[chexpert_plus['path_to_image'].isin(chexpert_5x200['Path'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIMIC-CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip-files\t\t      mimic-cxr-2.1.0-test-set-labeled.csv\n",
      "final-datasets\t\t      mimic_cxr_labels_reports_splits.csv\n",
      "IMAGE_FILENAMES\t\t      mimic-cxr-lt\n",
      "images\t\t\t      mimic_cxr_sectioned.csv\n",
      "LICENSE.txt\t\t      mimic_cxr_sections.csv\n",
      "mimic-cxr-2.0.0-chexpert.csv  patients.csv\n",
      "mimic-cxr-2.0.0-merged.csv    README\n",
      "mimic-cxr-2.0.0-metadata.csv  reports\n",
      "mimic-cxr-2.0.0-negbio.csv    resize_mimic.py\n",
      "mimic-cxr-2.0.0-split.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377110\n"
     ]
    }
   ],
   "source": [
    "# count total images \n",
    "\n",
    "images = glob.glob(\"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/images/files/*/*/*/*.jpg\")\n",
    "print(len(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377095, 18)\n",
      "Index(['dicom_id', 'study_id', 'subject_id', 'split', 'Atelectasis',\n",
      "       'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
      "       'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding',\n",
      "       'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax',\n",
      "       'Support Devices'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "split\n",
       "train       368945\n",
       "test          5159\n",
       "validate      2991\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = \"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-2.0.0-merged.csv\"\n",
    "merged = pd.read_csv(merged)\n",
    "merged = merged.drop(columns=['Unnamed: 0'])\n",
    "merged['subject_id'] = merged['subject_id'].astype(str)\n",
    "print(merged.shape)\n",
    "print(merged.columns)\n",
    "merged['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264849, 33) (36769, 33) (75492, 33) (377110, 33)\n",
      "Index(['dicom_id', 'subject_id', 'study_id', 'ViewPosition',\n",
      "       'ViewCodeSequence_CodeMeaning', 'path', 'Atelectasis',\n",
      "       'Calcification of the Aorta', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
      "       'Emphysema', 'Enlarged Cardiomediastinum', 'Fibrosis', 'Fracture',\n",
      "       'Hernia', 'Infiltration', 'Lung Lesion', 'Lung Opacity', 'Mass',\n",
      "       'No Finding', 'Nodule', 'Pleural Effusion', 'Pleural Other',\n",
      "       'Pleural Thickening', 'Pneumomediastinum', 'Pneumonia',\n",
      "       'Pneumoperitoneum', 'Pneumothorax', 'Subcutaneous Emphysema',\n",
      "       'Support Devices', 'Tortuous Aorta', 'split'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cxr_lt_train = \"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-lt/train.csv\"\n",
    "cxr_lt_train = pd.read_csv(cxr_lt_train)\n",
    "cxr_lt_val = \"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-lt/development.csv\"\n",
    "cxr_lt_val = pd.read_csv(cxr_lt_val)\n",
    "cxr_lt_test = \"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-lt/test.csv\"\n",
    "cxr_lt_test = pd.read_csv(cxr_lt_test)\n",
    "\n",
    "cxr_lt_train['split'] = 'train'\n",
    "cxr_lt_val['split'] = 'validate'\n",
    "cxr_lt_test['split'] = 'test'\n",
    "\n",
    "# Combine all three\n",
    "cxr_lt = pd.concat([cxr_lt_train, cxr_lt_val, cxr_lt_test])\n",
    "\n",
    "# Write to csv\n",
    "cxr_lt.to_csv(\"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-lt/mimic-cxr-lt-merged.csv\", index=False, header=True, sep=\"\\t\")\n",
    "\n",
    "print(cxr_lt_train.shape, cxr_lt_val.shape, cxr_lt_test.shape, cxr_lt.shape)\n",
    "print(cxr_lt_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377110\n"
     ]
    }
   ],
   "source": [
    "# find unique dicom_ids in cxr_lt\n",
    "print(len(cxr_lt['dicom_id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train       36014\n",
       "test          449\n",
       "validate      303\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the split column in the original merged for cxr_lt_val and cxr_lt_test. \n",
    "# first create a new df for the overlapping dicom_ids and then do value counts on the split column\n",
    "\n",
    "overlapping_dicom_ids = set(cxr_lt_val['dicom_id']).intersection(set(merged['dicom_id']))\n",
    "overlapping_df = merged[merged['dicom_id'].isin(overlapping_dicom_ids)]\n",
    "overlapping_df['split'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train       73905\n",
       "test          998\n",
       "validate      589\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping_dicom_ids = set(cxr_lt_test['dicom_id']).intersection(set(merged['dicom_id']))\n",
    "overlapping_df = merged[merged['dicom_id'].isin(overlapping_dicom_ids)]\n",
    "overlapping_df['split'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364627, 6)\n",
      "65379\n",
      "364627\n",
      "3511\n"
     ]
    }
   ],
   "source": [
    "patients = pd.read_csv(\"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/patients.csv\")\n",
    "patients['subject_id'] = patients['subject_id'].astype(str)\n",
    "print(patients.shape)\n",
    "patients.head()\n",
    "\n",
    "patients_age = dict(zip(patients['subject_id'], patients['anchor_age']))\n",
    "patients_gender = dict(zip(patients['subject_id'], patients['gender']))\n",
    "\n",
    "# # create a \"Age\" column in merged df and copy the value from the patients_age dictionary\n",
    "merged['age'] = merged['subject_id'].map(patients_age)\n",
    "merged['sex'] = merged['subject_id'].map(patients_gender)\n",
    "\n",
    "# Check how many subject_ids are present in the merged df\n",
    "print(len(merged['subject_id'].unique()))\n",
    "print(len(patients['subject_id'].unique()))\n",
    "\n",
    "# Check how many subject_ids are present in the merged df but not in the patients df\n",
    "print(len(set(merged['subject_id'].unique()) - set(patients['subject_id'].unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a \"path\" column in merged df and copy the value from the path column in cxr_lt. first create a dictionary to map dicom_id to path\n",
    "\n",
    "dicom_id_to_path = dict(zip(cxr_lt['dicom_id'], cxr_lt['path']))\n",
    "\n",
    "# create a \"path\" column in merged df and copy the value from the path column in cxr_lt\n",
    "merged['path'] = merged['dicom_id'].map(dicom_id_to_path)\n",
    "\n",
    "# Write to csv\n",
    "merged.to_csv(\"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-2.0.0-merged-with-paths.csv\", index=False, header=True, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AAA Job Opportunity!!! Cloud Computing - Masters or PhD Degree.pdf'\n",
      "'AAA Physician AI Research Opportunity!!!.pdf'\n",
      "'AAA Postdoctoral Fellowship Opportunity!!! - NIH Medical Image Analysis Postdoc.pdf'\n",
      " ARXIV_V5_CHESTXRAY.pdf\n",
      " BBox_List_2017.csv\n",
      " Data_Entry_2017_v2020.csv\n",
      " FAQ_CHESTXRAY.pdf\n",
      " final-datasets\n",
      " images\n",
      " LOG_CHESTXRAY.pdf\n",
      " LongTailCXR\n",
      " PruneCXR\n",
      " README_CHESTXRAY.pdf\n",
      " test_list.txt\n",
      " train_val_list.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/ChestXRay-14/CXR8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112120\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../data/ChestXRay-14/CXR8/images/files/*.jpg\")\n",
    "print(len(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ChestXRay-14/CXR8/images/files/00005566_003.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00026727_000.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00000236_000.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00022704_001.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00014006_001.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00013966_017.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00002835_003.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00015732_006.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00014790_017.jpg',\n",
       " '../data/ChestXRay-14/CXR8/images/files/00004857_032.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(images, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def resize_image(input_path):\n",
    "#     with Image.open(input_path) as img:\n",
    "#         img = img.resize((224, 224), Image.BICUBIC)\n",
    "#         img.save(input_path)  # Overwrite the original image\n",
    "\n",
    "# num_workers = 8\n",
    "\n",
    "# with Pool(processes=num_workers) as pool:\n",
    "#     list(tqdm(\n",
    "#         pool.imap(resize_image, images),\n",
    "#         total=len(images),\n",
    "#         desc=\"Resizing images\",\n",
    "#         unit=\"image\"\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78506, 23)\n",
      "(12533, 23)\n",
      "(21081, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>...</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pneumoperitoneum</th>\n",
       "      <th>Pneumomediastinum</th>\n",
       "      <th>Subcutaneous Emphysema</th>\n",
       "      <th>Tortuous Aorta</th>\n",
       "      <th>Calcification of the Aorta</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>subj_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000013_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000013_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000013_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000013_003.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000013_004.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0  00000013_000.png            0             0              0      0   \n",
       "1  00000013_001.png            0             0              0      0   \n",
       "2  00000013_002.png            0             0              0      0   \n",
       "3  00000013_003.png            0             0              0      0   \n",
       "4  00000013_004.png            0             0              0      0   \n",
       "\n",
       "   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  ...  Pneumonia  \\\n",
       "0         0          0         0       0             0  ...          0   \n",
       "1         0          1         0       0             0  ...          0   \n",
       "2         0          1         0       0             0  ...          0   \n",
       "3         0          0         0       0             0  ...          0   \n",
       "4         1          1         0       0             1  ...          0   \n",
       "\n",
       "   Pneumothorax  Pneumoperitoneum  Pneumomediastinum  Subcutaneous Emphysema  \\\n",
       "0             0                 0                  0                       0   \n",
       "1             1                 0                  0                       1   \n",
       "2             1                 0                  0                       1   \n",
       "3             0                 0                  0                       0   \n",
       "4             1                 0                  0                       1   \n",
       "\n",
       "   Tortuous Aorta  Calcification of the Aorta  No Finding  subj_id  split  \n",
       "0               0                           0           1       13   test  \n",
       "1               0                           0           0       13   test  \n",
       "2               0                           0           0       13   test  \n",
       "3               0                           0           0       13   test  \n",
       "4               0                           0           0       13   test  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nih_lt_train = \"../data/ChestXRay-14/CXR8/PruneCXR/miccai2023_nih-cxr-lt_labels_train.csv\"\n",
    "nih_lt_train = pd.read_csv(nih_lt_train)\n",
    "nih_lt_train['split'] = 'train'\n",
    "print(nih_lt_train.shape)\n",
    "nih_lt_train.head()\n",
    "\n",
    "nih_lt_val = \"../data/ChestXRay-14/CXR8/PruneCXR/miccai2023_nih-cxr-lt_labels_val.csv\"\n",
    "nih_lt_val = pd.read_csv(nih_lt_val)\n",
    "nih_lt_val['split'] = 'valid'\n",
    "print(nih_lt_val.shape)\n",
    "nih_lt_val.head()\n",
    "\n",
    "nih_lt_test = \"../data/ChestXRay-14/CXR8/PruneCXR/miccai2023_nih-cxr-lt_labels_test.csv\"\n",
    "nih_lt_test = pd.read_csv(nih_lt_test)\n",
    "nih_lt_test['split'] = 'test'\n",
    "print(nih_lt_test.shape)\n",
    "nih_lt_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112120, 23)\n",
      "split\n",
      "train    78506\n",
      "test     21081\n",
      "valid    12533\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>...</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pneumoperitoneum</th>\n",
       "      <th>Pneumomediastinum</th>\n",
       "      <th>Subcutaneous Emphysema</th>\n",
       "      <th>Tortuous Aorta</th>\n",
       "      <th>Calcification of the Aorta</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>subj_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000004_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               path  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0  00000001_000.png            0             1              0      0   \n",
       "1  00000001_001.png            0             1              0      0   \n",
       "2  00000001_002.png            0             1              0      0   \n",
       "3  00000002_000.png            0             0              0      0   \n",
       "4  00000004_000.png            0             0              0      0   \n",
       "\n",
       "   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  ...  Pneumonia  \\\n",
       "0         0          0         0       0             0  ...          0   \n",
       "1         0          1         0       0             0  ...          0   \n",
       "2         1          0         0       0             0  ...          0   \n",
       "3         0          0         0       0             0  ...          0   \n",
       "4         0          0         0       0             0  ...          0   \n",
       "\n",
       "   Pneumothorax  Pneumoperitoneum  Pneumomediastinum  Subcutaneous Emphysema  \\\n",
       "0             0                 0                  0                       0   \n",
       "1             0                 0                  0                       0   \n",
       "2             0                 0                  0                       0   \n",
       "3             0                 0                  0                       0   \n",
       "4             0                 0                  0                       0   \n",
       "\n",
       "   Tortuous Aorta  Calcification of the Aorta  No Finding  subj_id  split  \n",
       "0               0                           0           0        1  train  \n",
       "1               0                           0           0        1  train  \n",
       "2               0                           0           0        1  train  \n",
       "3               0                           0           1        2  train  \n",
       "4               0                           0           0        4  train  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge all three in a single df called nih_lt\n",
    "nih_lt = pd.concat([nih_lt_train, nih_lt_val, nih_lt_test])\n",
    "nih_lt.rename(columns={'id': 'path'}, inplace=True)\n",
    "print(nih_lt.shape)\n",
    "print(nih_lt.split.value_counts())\n",
    "nih_lt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "nih_lt.to_csv(\"../data/ChestXRay-14/CXR8/nih-lt-merged.csv\", index=False, header=True, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86524, 1)\n",
      "(25596, 1)\n",
      "(112120, 11)\n"
     ]
    }
   ],
   "source": [
    "nih_train = \"../data/ChestXRay-14/CXR8/train_val_list.txt\"\n",
    "nih_train = pd.read_csv(nih_train, header=None)\n",
    "nih_train.columns = [\"path\"]\n",
    "print(nih_train.shape)\n",
    "nih_train.head()\n",
    "\n",
    "nih_test = \"../data/ChestXRay-14/CXR8/test_list.txt\"\n",
    "nih_test = pd.read_csv(nih_test, header=None)\n",
    "nih_test.columns = [\"path\"]\n",
    "print(nih_test.shape)\n",
    "nih_test.head()\n",
    "\n",
    "nih_labels = \"../data/ChestXRay-14/CXR8/Data_Entry_2017_v2020.csv\"\n",
    "nih_labels = pd.read_csv(nih_labels)\n",
    "print(nih_labels.shape)\n",
    "nih_labels.head()\n",
    "\n",
    "# Create a mapping from Image Index to \"Finding Labels\"\n",
    "nih_labels_mapping = dict(zip(nih_labels['Image Index'], nih_labels['Finding Labels']))\n",
    "\n",
    "def split_label(label):\n",
    "    return label.split(\"|\")\n",
    "\n",
    "for k, v in nih_labels_mapping.items():\n",
    "    nih_labels_mapping[k] = split_label(v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No Finding', 'Hernia', 'Pleural_Thickening', 'Consolidation', 'Mass', 'Atelectasis', 'Infiltration', 'Emphysema', 'Pneumonia', 'Edema', 'Effusion', 'Pneumothorax', 'Nodule', 'Cardiomegaly', 'Fibrosis'}\n"
     ]
    }
   ],
   "source": [
    "# load all values into a list and make it a set \n",
    "all_labels = [item for sublist in nih_labels_mapping.values() for item in sublist]\n",
    "print(set(all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10032</th>\n",
       "      <td>00003213_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52497</th>\n",
       "      <td>00016256_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62656</th>\n",
       "      <td>00019474_000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70633</th>\n",
       "      <td>00022235_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>00018972_058.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   path  No Finding  Hernia  Pleural_Thickening  \\\n",
       "10032  00003213_000.jpg           1       0                   0   \n",
       "52497  00016256_000.jpg           1       0                   0   \n",
       "62656  00019474_000.jpg           0       0                   0   \n",
       "70633  00022235_001.jpg           0       0                   0   \n",
       "61167  00018972_058.jpg           1       0                   0   \n",
       "\n",
       "       Consolidation  Mass  Atelectasis  Infiltration  Emphysema  Pneumonia  \\\n",
       "10032              0     0            0             0          0          0   \n",
       "52497              0     0            0             0          0          0   \n",
       "62656              0     0            0             1          0          0   \n",
       "70633              0     0            0             0          0          0   \n",
       "61167              0     0            0             0          0          0   \n",
       "\n",
       "       Edema  Effusion  Pneumothorax  Nodule  Cardiomegaly  Fibrosis  age sex  \\\n",
       "10032      0         0             0       0             0         0   61   M   \n",
       "52497      0         0             0       0             0         0   24   M   \n",
       "62656      0         0             0       0             0         0   29   F   \n",
       "70633      0         0             0       1             0         0   46   M   \n",
       "61167      0         0             0       0             0         0   52   F   \n",
       "\n",
       "       split  \n",
       "10032  train  \n",
       "52497  train  \n",
       "62656  train  \n",
       "70633  train  \n",
       "61167  train  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nih_labels_mapping looks like this\n",
    "# {'00000001_000.png': ['Cardiomegaly'],\n",
    "#  '00000001_001.png': ['Cardiomegaly', 'Emphysema'],\n",
    "#  '00000001_002.png': ['Cardiomegaly', 'Effusion'],\n",
    "#  '00000002_000.png': ['No Finding'],\n",
    "#  ...\n",
    "#  }\n",
    "\n",
    "# create a new df for nih_train and nih_test with the path and the labels. \n",
    "# each label should be a column and the value should be 1 if the label is present and 0 otherwise\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "nih_train_new = nih_train.copy()\n",
    "nih_test_new = nih_test.copy()\n",
    "\n",
    "label_cols = list(set(all_labels))\n",
    "\n",
    "for label in label_cols:\n",
    "    nih_train_new[label] = nih_train_new['path'].apply(lambda x: 1 if label in nih_labels_mapping[x] else 0)\n",
    "    nih_test_new[label] = nih_test_new['path'].apply(lambda x: 1 if label in nih_labels_mapping[x] else 0)\n",
    "    \n",
    "# Copy Patient Age and Patient Gender to the new dfs. they are in the original nih_labels df. \n",
    "# first make two dictionaries to map Image Index to Patient Age and Patient Gender\n",
    "nih_labels_mapping_age = dict(zip(nih_labels['Image Index'], nih_labels['Patient Age']))\n",
    "nih_labels_mapping_gender = dict(zip(nih_labels['Image Index'], nih_labels['Patient Gender']))\n",
    "nih_train_new['age'] = nih_train_new['path'].map(nih_labels_mapping_age)\n",
    "nih_train_new['sex'] = nih_train_new['path'].map(nih_labels_mapping_gender)\n",
    "nih_train_new['split'] = 'train'\n",
    "\n",
    "nih_test_new['age'] = nih_test_new['path'].map(nih_labels_mapping_age)\n",
    "nih_test_new['sex'] = nih_test_new['path'].map(nih_labels_mapping_gender)\n",
    "nih_test_new['split'] = 'test'\n",
    "\n",
    "\n",
    "nih_train_new, nih_val_new = train_test_split(nih_train_new, test_size=0.05, random_state=42)\n",
    "nih_val_new['split'] = 'valid'\n",
    "\n",
    "\n",
    "nih_merged = pd.concat([nih_train_new, nih_val_new, nih_test_new])\n",
    "\n",
    "# in path, replace png with jpg\n",
    "nih_merged['path'] = nih_merged['path'].apply(lambda x: x.replace(\".png\", \".jpg\"))\n",
    "\n",
    "nih_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    82197\n",
      "test     25596\n",
      "valid     4327\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nih_merged.split.value_counts())\n",
    "# Write to csv\n",
    "nih_merged.to_csv(\"../data/ChestXRay-14/CXR8/nih-merged.csv\", index=False, header=True, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10032</th>\n",
       "      <td>00003213_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52497</th>\n",
       "      <td>00016256_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62656</th>\n",
       "      <td>00019474_000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70633</th>\n",
       "      <td>00022235_001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>00018972_058.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25591</th>\n",
       "      <td>00030800_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25592</th>\n",
       "      <td>00030802_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25593</th>\n",
       "      <td>00030803_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25594</th>\n",
       "      <td>00030804_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25595</th>\n",
       "      <td>00030805_000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112120 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   path  No Finding  Hernia  Pleural_Thickening  \\\n",
       "10032  00003213_000.jpg           1       0                   0   \n",
       "52497  00016256_000.jpg           1       0                   0   \n",
       "62656  00019474_000.jpg           0       0                   0   \n",
       "70633  00022235_001.jpg           0       0                   0   \n",
       "61167  00018972_058.jpg           1       0                   0   \n",
       "...                 ...         ...     ...                 ...   \n",
       "25591  00030800_000.jpg           1       0                   0   \n",
       "25592  00030802_000.jpg           1       0                   0   \n",
       "25593  00030803_000.jpg           1       0                   0   \n",
       "25594  00030804_000.jpg           1       0                   0   \n",
       "25595  00030805_000.jpg           1       0                   0   \n",
       "\n",
       "       Consolidation  Mass  Atelectasis  Infiltration  Emphysema  Pneumonia  \\\n",
       "10032              0     0            0             0          0          0   \n",
       "52497              0     0            0             0          0          0   \n",
       "62656              0     0            0             1          0          0   \n",
       "70633              0     0            0             0          0          0   \n",
       "61167              0     0            0             0          0          0   \n",
       "...              ...   ...          ...           ...        ...        ...   \n",
       "25591              0     0            0             0          0          0   \n",
       "25592              0     0            0             0          0          0   \n",
       "25593              0     0            0             0          0          0   \n",
       "25594              0     0            0             0          0          0   \n",
       "25595              0     0            0             0          0          0   \n",
       "\n",
       "       Edema  Effusion  Pneumothorax  Nodule  Cardiomegaly  Fibrosis  age sex  \\\n",
       "10032      0         0             0       0             0         0   61   M   \n",
       "52497      0         0             0       0             0         0   24   M   \n",
       "62656      0         0             0       0             0         0   29   F   \n",
       "70633      0         0             0       1             0         0   46   M   \n",
       "61167      0         0             0       0             0         0   52   F   \n",
       "...      ...       ...           ...     ...           ...       ...  ...  ..   \n",
       "25591      0         0             0       0             0         0   33   F   \n",
       "25592      0         0             0       0             0         0   28   M   \n",
       "25593      0         0             0       0             0         0   42   F   \n",
       "25594      0         0             0       0             0         0   29   F   \n",
       "25595      0         0             0       0             0         0   26   M   \n",
       "\n",
       "       split  \n",
       "10032  train  \n",
       "52497  train  \n",
       "62656  train  \n",
       "70633  train  \n",
       "61167  train  \n",
       "...      ...  \n",
       "25591   test  \n",
       "25592   test  \n",
       "25593   test  \n",
       "25594   test  \n",
       "25595   test  \n",
       "\n",
       "[112120 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nih_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train       264849\n",
      "test         75492\n",
      "validate     36769\n",
      "Name: count, dtype: int64\n",
      "split\n",
      "train    222230\n",
      "test       1000\n",
      "valid       234\n",
      "Name: count, dtype: int64\n",
      "split\n",
      "train    78506\n",
      "test     21081\n",
      "valid    12533\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#load mimic, chexpert, nih, covid data to compare value counts of split \n",
    "\n",
    "mimic = pd.read_csv(\"../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/mimic-cxr-lt/mimic-cxr-lt-merged.csv\", sep=\"\\t\")\n",
    "chexpert = pd.read_csv(\"../data/CheXpert/CheXpert-v1.0-small/chexpert_plus_labels_with_5x200.csv\", sep=\"\\t\")\n",
    "nih = pd.read_csv(\"../data/ChestXRay-14/CXR8/images/nih-lt-merged.csv\", sep=\"\\t\")\n",
    "\n",
    "print(mimic.split.value_counts())\n",
    "print(chexpert.split.value_counts())\n",
    "print(nih.split.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>split</th>\n",
       "      <th>report</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient42142/study5/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy tube remains in pla...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient42142/study8/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.tracheostomy and subdiaphragmati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient42142/study2/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.single portable semiupright ap v...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient42142/study4/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1. patchy subsegmental bibasilar (...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient42142/study3/view1_frontal.jpg</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>train</td>\n",
       "      <td>impression: 1.upright frontal view of the ches...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223459</th>\n",
       "      <td>train/patient29065/study20/view1_frontal.jpg</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>\\n \\n1.  small right pleural effusion.\\n \\n2. ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223460</th>\n",
       "      <td>train/patient50590/study2/view1_frontal.jpg</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>\\n \\n 1.   though the patient is rotated, aga...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223461</th>\n",
       "      <td>train/patient09101/study1/view1_frontal.jpg</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>\\n \\n1.  large right pleural effusion with a p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223462</th>\n",
       "      <td>train/patient31752/study3/view1_frontal.jpg</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>\\n \\n1.postsurgical changes of the right lower...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223463</th>\n",
       "      <td>train/patient18539/study1/view1_frontal.jpg</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>test</td>\n",
       "      <td>\\n \\n small to moderate left pleural effusion,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223464 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       path_to_image   age     sex     race  \\\n",
       "0        train/patient42142/study5/view1_frontal.jpg  62.0  Female    White   \n",
       "1        train/patient42142/study8/view1_frontal.jpg  62.0  Female    White   \n",
       "2        train/patient42142/study2/view1_frontal.jpg  62.0  Female    White   \n",
       "3        train/patient42142/study4/view1_frontal.jpg  62.0  Female    White   \n",
       "4        train/patient42142/study3/view1_frontal.jpg  62.0  Female    White   \n",
       "...                                              ...   ...     ...      ...   \n",
       "223459  train/patient29065/study20/view1_frontal.jpg  60.0    Male  Unknown   \n",
       "223460   train/patient50590/study2/view1_frontal.jpg  67.0    Male  Unknown   \n",
       "223461   train/patient09101/study1/view1_frontal.jpg  43.0  Female  Unknown   \n",
       "223462   train/patient31752/study3/view1_frontal.jpg  48.0    Male  Unknown   \n",
       "223463   train/patient18539/study1/view1_frontal.jpg  71.0  Female  Unknown   \n",
       "\n",
       "        split                                             report  \\\n",
       "0       train  impression: 1.tracheostomy tube remains in pla...   \n",
       "1       train  impression: 1.tracheostomy and subdiaphragmati...   \n",
       "2       train  impression: 1.single portable semiupright ap v...   \n",
       "3       train  impression: 1. patchy subsegmental bibasilar (...   \n",
       "4       train  impression: 1.upright frontal view of the ches...   \n",
       "...       ...                                                ...   \n",
       "223459   test  \\n \\n1.  small right pleural effusion.\\n \\n2. ...   \n",
       "223460   test   \\n \\n 1.   though the patient is rotated, aga...   \n",
       "223461   test  \\n \\n1.  large right pleural effusion with a p...   \n",
       "223462   test  \\n \\n1.postsurgical changes of the right lower...   \n",
       "223463   test  \\n \\n small to moderate left pleural effusion,...   \n",
       "\n",
       "        Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  \\\n",
       "0                              0.0           0.0           0.0          0.0   \n",
       "1                              0.0           0.0           0.0          0.0   \n",
       "2                              0.0           0.0           1.0          0.0   \n",
       "3                              0.0           0.0           0.0          0.0   \n",
       "4                              0.0           0.0           0.0          0.0   \n",
       "...                            ...           ...           ...          ...   \n",
       "223459                         0.0           0.0           0.0          0.0   \n",
       "223460                         0.0           0.0           0.0          0.0   \n",
       "223461                         0.0           0.0           0.0          0.0   \n",
       "223462                         0.0           0.0           0.0          0.0   \n",
       "223463                         0.0           0.0           0.0          0.0   \n",
       "\n",
       "        Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0         0.0            0.0        0.0          0.0           0.0   \n",
       "1         0.0            0.0        0.0          1.0           0.0   \n",
       "2         0.0            0.0        0.0          1.0           0.0   \n",
       "3         0.0            1.0        0.0          1.0           0.0   \n",
       "4         0.0            0.0        0.0          1.0           0.0   \n",
       "...       ...            ...        ...          ...           ...   \n",
       "223459    0.0            0.0        0.0          0.0           0.0   \n",
       "223460    0.0            0.0        0.0          0.0           0.0   \n",
       "223461    0.0            0.0        0.0          0.0           0.0   \n",
       "223462    0.0            0.0        0.0          0.0           0.0   \n",
       "223463    0.0            0.0        0.0          0.0           0.0   \n",
       "\n",
       "        Pleural Effusion  Pleural Other  Fracture  Support Devices  No Finding  \n",
       "0                    0.0            0.0       0.0              1.0         0.0  \n",
       "1                    0.0            0.0       0.0              1.0         0.0  \n",
       "2                    1.0            0.0       0.0              1.0         0.0  \n",
       "3                    0.0            0.0       0.0              1.0         0.0  \n",
       "4                    0.0            0.0       0.0              1.0         0.0  \n",
       "...                  ...            ...       ...              ...         ...  \n",
       "223459               1.0            0.0       0.0              0.0         0.0  \n",
       "223460               1.0            0.0       0.0              0.0         0.0  \n",
       "223461               1.0            0.0       0.0              0.0         0.0  \n",
       "223462               1.0            0.0       0.0              0.0         0.0  \n",
       "223463               1.0            0.0       0.0              0.0         0.0  \n",
       "\n",
       "[223464 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexpert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67863 8473 8482\n"
     ]
    }
   ],
   "source": [
    "train_images = glob.glob(\"../data/COVIDx-CXR-4/train/*\")\n",
    "val_images = glob.glob(\"../data/COVIDx-CXR-4/val/*\")\n",
    "test_images = glob.glob(\"../data/COVIDx-CXR-4/test/*\")\n",
    "\n",
    "print(len(train_images), len(val_images), len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "positive    57199\n",
      "negative    10664\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "positive    4241\n",
      "negative    4232\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "positive    4241\n",
      "negative    4241\n",
      "Name: count, dtype: int64\n",
      "(84818, 3)\n",
      "split\n",
      "train    67863\n",
      "test      8482\n",
      "valid     8473\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    65681\n",
      "0    19137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "covid_train = \"../data/COVIDx-CXR-4/train.txt\"\n",
    "covid_train = pd.read_csv(covid_train, header=None, sep=\" \")\n",
    "covid_train.columns = [\"idx\", \"path\", \"label\", \"source\"]\n",
    "covid_train['split'] = 'train'\n",
    "covid_train.head()\n",
    "print(covid_train.label.value_counts())\n",
    "\n",
    "covid_val = \"../data/COVIDx-CXR-4/val.txt\"\n",
    "covid_val = pd.read_csv(covid_val, header=None, sep=\" \")\n",
    "covid_val.columns = [\"idx\", \"path\", \"label\", \"source\"]\n",
    "covid_val['split'] = 'valid'\n",
    "covid_val.head()\n",
    "print(covid_val.label.value_counts())\n",
    "\n",
    "covid_test = \"../data/COVIDx-CXR-4/test.txt\"\n",
    "covid_test = pd.read_csv(covid_test, header=None, sep=\" \")\n",
    "covid_test.columns = [\"idx\", \"path\", \"label\", \"source\"]\n",
    "covid_test['split'] = 'test'\n",
    "covid_test.head()\n",
    "print(covid_test.label.value_counts())\n",
    "\n",
    "# combine all three\n",
    "covid = pd.concat([covid_train, covid_val, covid_test])\n",
    "covid.drop(columns=['idx', 'source'], inplace=True)\n",
    "\n",
    "#replace \"negative\" with 0 and \"positive\" with 1\n",
    "covid['label'] = covid['label'].apply(lambda x: 0 if x == \"negative\" else 1)\n",
    "\n",
    "print(covid.shape)\n",
    "print(covid.split.value_counts())\n",
    "print(covid.label.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_paths = set(covid_train['path'].to_list())\n",
    "val_paths = set(covid_val['path'].to_list())\n",
    "test_paths = set(covid_test['path'].to_list())\n",
    "\n",
    "#check overlap between all the pairs of sets \n",
    "print(len(train_paths.intersection(val_paths)))\n",
    "print(len(train_paths.intersection(test_paths)))\n",
    "print(len(val_paths.intersection(test_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# first check if the images exist in the original folder\n",
    "not_found = []\n",
    "for image in train_images:\n",
    "    if not os.path.exists(image):\n",
    "        not_found.append(image)\n",
    "print(len(not_found))\n",
    "\n",
    "for image in val_images:\n",
    "    if not os.path.exists(image):\n",
    "        not_found.append(image)\n",
    "print(len(not_found))\n",
    "\n",
    "for image in test_images:\n",
    "    if not os.path.exists(image):\n",
    "        not_found.append(image)\n",
    "print(len(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 67863/67863 [00:02<00:00, 28975.28it/s]\n",
      "100%|| 8473/8473 [00:00<00:00, 31983.85it/s]\n",
      "100%|| 8482/8482 [00:00<00:00, 31444.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#move all the images from train/ val/ and test/ to a new folder called images\n",
    "\n",
    "new_folder = \"../data/COVIDx-CXR-4/images\"\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "for image in tqdm(train_images):\n",
    "    shutil.move(image, new_folder)\n",
    "\n",
    "for image in tqdm(val_images):\n",
    "    shutil.move(image, new_folder)\n",
    "\n",
    "for image in tqdm(test_images):\n",
    "    shutil.move(image, new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.jpg', '.PNG', '.jpeg', '.JPG', '.png'}\n",
      "Counter({'.png': 70747, '.jpg': 13947, '.jpeg': 122, '.JPG': 1, '.PNG': 1})\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../data/COVIDx-CXR-4/images/*\")\n",
    "\n",
    "# Print all the extensions of the images\n",
    "print(set([os.path.splitext(image)[1] for image in images]))\n",
    "\n",
    "# print the counts of the extensions\n",
    "from collections import Counter\n",
    "print(Counter([os.path.splitext(image)[1] for image in images]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images: 100%|| 84818/84818 [01:48<00:00, 780.33image/s]\n"
     ]
    }
   ],
   "source": [
    "def resize_image(input_path):\n",
    "    try:\n",
    "        with Image.open(input_path) as img:\n",
    "            img = img.resize((224, 224), Image.BICUBIC)\n",
    "            # Convert to RGB mode for all images\n",
    "            img = img.convert('RGB')\n",
    "            # Convert to jpg if not already jpg/jpeg\n",
    "            if not (input_path.lower().endswith('.jpg') or input_path.lower().endswith('.jpeg')):\n",
    "                output_path = os.path.splitext(input_path)[0] + '.jpg'\n",
    "                img.save(output_path, 'JPEG')  # Save as jpg\n",
    "                os.remove(input_path)  # Remove original file\n",
    "            else:\n",
    "                img.save(input_path)  # Overwrite original jpg/jpeg\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_path}: {e}\")\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "with Pool(processes=num_workers) as pool:\n",
    "    list(tqdm(\n",
    "        pool.imap(resize_image, images),\n",
    "        total=len(images),\n",
    "        desc=\"Resizing images\",\n",
    "        unit=\"image\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 84818/84818 [00:00<00:00, 440956.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replace all the jpeg with jpg\n",
    "for image in tqdm(images):\n",
    "    if os.path.splitext(image)[1] == '.jpeg':\n",
    "        os.rename(image, os.path.splitext(image)[0] + '.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e64990d1b40c1758a2aaa9c7f7a85_jumbo.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7223b8ad031187d9a142d7f7ca02c9_jumbo.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3392dc7d262e28423caca517f98c2e_jumbo.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ec3a480c0926ded74429df416cfb05_jumbo.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a72aeb349a63c79ed24e473c434efe_jumbo.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>sub-S24538_ses-E50624_run-1_bp-chest_vp-ap_dx-...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>sub-S24539_ses-E50625_run-1_bp-chest_vp-pa_cr-...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>sub-S24540_ses-E50626_run-1_bp-chest_vp-ap_cr-...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>sub-S24540_ses-E60362_run-1_bp-chest_vp-ap_dx-...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>sub-S24541_ses-E50627_run-1_bp-chest_vp-pa_dx-...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84800 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  label  split\n",
       "0              1e64990d1b40c1758a2aaa9c7f7a85_jumbo.jpg      0  train\n",
       "1              7223b8ad031187d9a142d7f7ca02c9_jumbo.jpg      0  train\n",
       "2              3392dc7d262e28423caca517f98c2e_jumbo.jpg      0  train\n",
       "3              ec3a480c0926ded74429df416cfb05_jumbo.jpg      0  train\n",
       "4              a72aeb349a63c79ed24e473c434efe_jumbo.jpg      0  train\n",
       "...                                                 ...    ...    ...\n",
       "8477  sub-S24538_ses-E50624_run-1_bp-chest_vp-ap_dx-...      0   test\n",
       "8478  sub-S24539_ses-E50625_run-1_bp-chest_vp-pa_cr-...      0   test\n",
       "8479  sub-S24540_ses-E50626_run-1_bp-chest_vp-ap_cr-...      0   test\n",
       "8480  sub-S24540_ses-E60362_run-1_bp-chest_vp-ap_dx-...      0   test\n",
       "8481  sub-S24541_ses-E50627_run-1_bp-chest_vp-pa_dx-...      0   test\n",
       "\n",
       "[84800 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the path column, replace all extensions with jpg\n",
    "covid['path'] = covid['path'].apply(lambda x: os.path.splitext(x)[0] + '.jpg')\n",
    "covid = covid.drop_duplicates(subset='path', keep=False)\n",
    "covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid.to_csv(\"../data/COVIDx-CXR-4/covid-merged.csv\", index=False, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.JPG', '.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# check if all the images in the images/ folder end with a .jpg\n",
    "images = glob.glob(\"../data/COVIDx-CXR-4/images/*\")\n",
    "print(set([os.path.splitext(image)[1] for image in images]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# replace the extension .JPG with .jpg\n",
    "for image in images:\n",
    "    if os.path.splitext(image)[1] == '.JPG':\n",
    "        os.rename(image, os.path.splitext(image)[0] + '.jpg')\n",
    "\n",
    "# check if all the images in the images/ folder end with a .jpg\n",
    "images = glob.glob(\"../data/COVIDx-CXR-4/images/*\")\n",
    "print(set([os.path.splitext(image)[1] for image in images]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# check if all the images in the covid-merged.csv file end with a .jpg\n",
    "print(set([os.path.splitext(image)[1] for image in covid['path'].to_list()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CheXechonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"../data/CheXchoNet/images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 71589/71589 [00:03<00:00, 19967.78it/s]\n",
      "Resizing images: 100%|| 71589/71589 [00:07<00:00, 9188.59image/s]\n"
     ]
    }
   ],
   "source": [
    "# if the height and widith are not 224, print the path\n",
    "for image in tqdm(images):\n",
    "    if Image.open(image).size != (224, 224):\n",
    "        print(image)\n",
    "\n",
    "\n",
    "# Load and resize all the images in the images/ folder\n",
    "def resize_image(input_path):\n",
    "    with Image.open(input_path) as img:\n",
    "        img = img.resize((224, 224), Image.BICUBIC)\n",
    "        img.save(input_path, 'JPEG')\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "with Pool(processes=num_workers) as pool:\n",
    "    list(tqdm(\n",
    "        pool.imap(resize_image, images),\n",
    "        total=len(images),\n",
    "        desc=\"Resizing images\",\n",
    "        unit=\"image\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>cxr_filename</th>\n",
       "      <th>cxr_time_offset</th>\n",
       "      <th>cxr_year</th>\n",
       "      <th>cxr_path</th>\n",
       "      <th>cxr_pixel_spacing_x</th>\n",
       "      <th>cxr_pixel_spacing_y</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>ivsd</th>\n",
       "      <th>lvpwd</th>\n",
       "      <th>lvidd</th>\n",
       "      <th>slvh</th>\n",
       "      <th>dlv</th>\n",
       "      <th>composite_slvh_dlv</th>\n",
       "      <th>heart_transplant</th>\n",
       "      <th>lung_transplant</th>\n",
       "      <th>pacemaker_or_icd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001a10b30d6cff4ce1c2bff5be86958</td>\n",
       "      <td>0001a10b30d6cff4ce1c2bff5be86958_6aee7800.jpg</td>\n",
       "      <td>4314 days 09:20:05.326807</td>\n",
       "      <td>2018</td>\n",
       "      <td>./cxrs/0001a10b30d6cff4ce1c2bff5be86958_6aee78...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>31</td>\n",
       "      <td>F</td>\n",
       "      <td>0.73626</td>\n",
       "      <td>0.754162</td>\n",
       "      <td>4.58632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008eb0430637bd17906cb0a5f1126e1</td>\n",
       "      <td>0008eb0430637bd17906cb0a5f1126e1_000bd69b.jpg</td>\n",
       "      <td>3431 days 15:41:04.059338</td>\n",
       "      <td>2017</td>\n",
       "      <td>./cxrs/0008eb0430637bd17906cb0a5f1126e1_000bd6...</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>1.07021</td>\n",
       "      <td>1.131820</td>\n",
       "      <td>4.34344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008eb0430637bd17906cb0a5f1126e1</td>\n",
       "      <td>0008eb0430637bd17906cb0a5f1126e1_301ec85b.jpg</td>\n",
       "      <td>3439 days 17:09:04.059338</td>\n",
       "      <td>2017</td>\n",
       "      <td>./cxrs/0008eb0430637bd17906cb0a5f1126e1_301ec8...</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>1.07021</td>\n",
       "      <td>1.131820</td>\n",
       "      <td>4.34344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a92e15c0a8df9f107f09acf295e36</td>\n",
       "      <td>000a92e15c0a8df9f107f09acf295e36_32b2a209.jpg</td>\n",
       "      <td>4880 days 13:29:52.822593</td>\n",
       "      <td>2015</td>\n",
       "      <td>./cxrs/000a92e15c0a8df9f107f09acf295e36_32b2a2...</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>1.25907</td>\n",
       "      <td>1.253680</td>\n",
       "      <td>5.02448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00163791112923cb52834f0e75123225</td>\n",
       "      <td>00163791112923cb52834f0e75123225_32f21836.jpg</td>\n",
       "      <td>5113 days 09:27:04.110448</td>\n",
       "      <td>2016</td>\n",
       "      <td>./cxrs/00163791112923cb52834f0e75123225_32f218...</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>76</td>\n",
       "      <td>F</td>\n",
       "      <td>1.01069</td>\n",
       "      <td>1.049160</td>\n",
       "      <td>3.63108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         patient_id  \\\n",
       "0  0001a10b30d6cff4ce1c2bff5be86958   \n",
       "1  0008eb0430637bd17906cb0a5f1126e1   \n",
       "2  0008eb0430637bd17906cb0a5f1126e1   \n",
       "3  000a92e15c0a8df9f107f09acf295e36   \n",
       "4  00163791112923cb52834f0e75123225   \n",
       "\n",
       "                                    cxr_filename            cxr_time_offset  \\\n",
       "0  0001a10b30d6cff4ce1c2bff5be86958_6aee7800.jpg  4314 days 09:20:05.326807   \n",
       "1  0008eb0430637bd17906cb0a5f1126e1_000bd69b.jpg  3431 days 15:41:04.059338   \n",
       "2  0008eb0430637bd17906cb0a5f1126e1_301ec85b.jpg  3439 days 17:09:04.059338   \n",
       "3  000a92e15c0a8df9f107f09acf295e36_32b2a209.jpg  4880 days 13:29:52.822593   \n",
       "4  00163791112923cb52834f0e75123225_32f21836.jpg  5113 days 09:27:04.110448   \n",
       "\n",
       "   cxr_year                                           cxr_path  \\\n",
       "0      2018  ./cxrs/0001a10b30d6cff4ce1c2bff5be86958_6aee78...   \n",
       "1      2017  ./cxrs/0008eb0430637bd17906cb0a5f1126e1_000bd6...   \n",
       "2      2017  ./cxrs/0008eb0430637bd17906cb0a5f1126e1_301ec8...   \n",
       "3      2015  ./cxrs/000a92e15c0a8df9f107f09acf295e36_32b2a2...   \n",
       "4      2016  ./cxrs/00163791112923cb52834f0e75123225_32f218...   \n",
       "\n",
       "   cxr_pixel_spacing_x  cxr_pixel_spacing_y  age sex     ivsd     lvpwd  \\\n",
       "0             0.200000             0.200000   31   F  0.73626  0.754162   \n",
       "1             0.194556             0.194556   74   F  1.07021  1.131820   \n",
       "2             0.194556             0.194556   74   F  1.07021  1.131820   \n",
       "3             0.194556             0.194556   67   M  1.25907  1.253680   \n",
       "4             0.194556             0.194556   76   F  1.01069  1.049160   \n",
       "\n",
       "     lvidd  slvh  dlv  composite_slvh_dlv  heart_transplant  lung_transplant  \\\n",
       "0  4.58632     0    0                   0                 0                0   \n",
       "1  4.34344     0    0                   0                 0                0   \n",
       "2  4.34344     0    0                   0                 0                0   \n",
       "3  5.02448     0    0                   0                 0                0   \n",
       "4  3.63108     0    0                   0                 0                0   \n",
       "\n",
       "   pacemaker_or_icd  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"../data/CheXchoNet/metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/CheXchoNet/images/c53d8be402c3780f3ea36065c0b429b9_eaa5ba7c.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    61728\n",
      "1     9861\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_556184/4210245320.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chexchonet['cxr_path'] = chexchonet['cxr_path'].apply(lambda x: x.replace(\"./cxrs/\", \"\"))\n",
      "/tmp/ipykernel_556184/4210245320.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chexchonet.rename(columns={'cxr_path': 'path', 'composite_slvh_dlv': 'label'}, inplace=True)\n",
      "/tmp/ipykernel_556184/4210245320.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_samples['split'] = 'train'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001a10b30d6cff4ce1c2bff5be86958_6aee7800.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008eb0430637bd17906cb0a5f1126e1_000bd69b.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008eb0430637bd17906cb0a5f1126e1_301ec85b.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a92e15c0a8df9f107f09acf295e36_32b2a209.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00163791112923cb52834f0e75123225_32f21836.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  label  split\n",
       "0  0001a10b30d6cff4ce1c2bff5be86958_6aee7800.jpg      0  train\n",
       "1  0008eb0430637bd17906cb0a5f1126e1_000bd69b.jpg      0  train\n",
       "2  0008eb0430637bd17906cb0a5f1126e1_301ec85b.jpg      0  train\n",
       "3  000a92e15c0a8df9f107f09acf295e36_32b2a209.jpg      0  train\n",
       "4  00163791112923cb52834f0e75123225_32f21836.jpg      0  train"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take these labels ['cxr_path', 'age', 'sex', 'composite_slvh_dlv']\n",
    "chexchonet = metadata[['cxr_path','composite_slvh_dlv']]\n",
    "# in cxr_path, replace the \"./cxrs/\" with nothing\n",
    "chexchonet['cxr_path'] = chexchonet['cxr_path'].apply(lambda x: x.replace(\"./cxrs/\", \"\"))\n",
    "chexchonet.rename(columns={'cxr_path': 'path', 'composite_slvh_dlv': 'label'}, inplace=True)\n",
    "print(chexchonet.label.value_counts())\n",
    "\n",
    "# First split out the positive and negative samples\n",
    "pos_samples = chexchonet[chexchonet.label == 1]\n",
    "neg_samples = chexchonet[chexchonet.label == 0]\n",
    "\n",
    "# Determine size of test set based on minority class\n",
    "n_test = min(len(pos_samples), len(neg_samples)) // 13  # 10% for test set\n",
    "\n",
    "# Sample equal numbers from each class for test set\n",
    "test_pos = pos_samples.sample(n=n_test, random_state=42)\n",
    "test_neg = neg_samples.sample(n=n_test, random_state=42)\n",
    "\n",
    "# Combine test samples and mark as test\n",
    "test_samples = pd.concat([test_pos, test_neg])\n",
    "test_samples['split'] = 'test'\n",
    "\n",
    "# Get remaining samples for training\n",
    "train_samples = chexchonet[~chexchonet.index.isin(test_samples.index)]\n",
    "train_samples['split'] = 'train'\n",
    "\n",
    "# Combine train and test\n",
    "chexchonet = pd.concat([train_samples, test_samples])\n",
    "\n",
    "chexchonet.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>758</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>60970</td>\n",
       "      <td>9103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label      0     1\n",
       "split             \n",
       "test     758   758\n",
       "train  60970  9103"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chexchonet.pivot_table(index='split', columns='label', values='path', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexchonet.to_csv(\"../data/CheXchoNet/chexchonet-merged.csv\", index=False, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TBX11K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 2)\n",
      "split\n",
      "train    6600\n",
      "test     1800\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tbx11k_train = pd.read_csv(\"../data/TBX11K/lists/TBX11K_train.txt\", header=None)\n",
    "tbx11k_val = pd.read_csv(\"../data/TBX11K/lists/TBX11K_val.txt\", header=None)\n",
    "\n",
    "tbx11k_train.columns = [\"path\"]\n",
    "tbx11k_val.columns = [\"path\"]\n",
    "\n",
    "tbx11k_train['split'] = 'train'\n",
    "tbx11k_val['split'] = 'test'\n",
    "\n",
    "tbx11k = pd.concat([tbx11k_train, tbx11k_val])\n",
    "print(tbx11k.shape)\n",
    "print(tbx11k.split.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    3800\n",
      "1    3800\n",
      "2     800\n",
      "Name: count, dtype: int64\n",
      "label     0     1    2\n",
      "split                 \n",
      "test    800   800  200\n",
      "train  3000  3000  600\n"
     ]
    }
   ],
   "source": [
    "#tbx11k[tbx11k['path'].str.contains(\"sick\")]\n",
    "\n",
    "# if path contains \"sick\" then label is 1, if path contains \"healthy\" then label is 0, if path contains tb then label is 2\n",
    "tbx11k['label'] = tbx11k['path'].apply(lambda x: 1 if \"sick\" in x else 0 if \"health\" in x else 2 if \"tb\" in x else None)\n",
    "print(tbx11k.label.value_counts())\n",
    "print(tbx11k.pivot_table(index='split', columns='label', values='path', aggfunc='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 88\n",
      "Counter({0: 54, 2: 34})\n",
      "Counter({0: 48, 2: 40})\n",
      "(176, 3)\n",
      "split\n",
      "train    88\n",
      "test     88\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    102\n",
      "2     74\n",
      "Name: count, dtype: int64\n",
      "label   0   2\n",
      "split        \n",
      "test   48  40\n",
      "train  54  34\n"
     ]
    }
   ],
   "source": [
    "da_db_train = glob.glob(\"../data/TBX11K/imgs/extra/da+db/train/*\")\n",
    "da_db_test = glob.glob(\"../data/TBX11K/imgs/extra/da+db/val/*\")\n",
    "\n",
    "print(len(da_db_train), len(da_db_test))\n",
    "\n",
    "def get_label(path):\n",
    "    # if filename starts with \"n\" label is 0, if path starts with p label is 2\n",
    "    filename = os.path.basename(path)\n",
    "    if filename.startswith(\"n\"):\n",
    "        return 0\n",
    "    elif filename.startswith(\"p\"):\n",
    "        return 2\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "da_db_train_labels = [get_label(path) for path in da_db_train]\n",
    "da_db_test_labels = [get_label(path) for path in da_db_test]\n",
    "\n",
    "print(Counter(da_db_train_labels))\n",
    "print(Counter(da_db_test_labels))\n",
    "\n",
    "da_db_train_df = pd.DataFrame({'path': da_db_train, 'label': da_db_train_labels})\n",
    "da_db_test_df = pd.DataFrame({'path': da_db_test, 'label': da_db_test_labels})\n",
    "\n",
    "da_db_train_df['split'] = 'train'\n",
    "da_db_test_df['split'] = 'test'\n",
    "\n",
    "da_db = pd.concat([da_db_train_df, da_db_test_df])\n",
    "print(da_db.shape)\n",
    "print(da_db.split.value_counts())\n",
    "print(da_db.label.value_counts())\n",
    "print(da_db.pivot_table(index='split', columns='label', values='path', aggfunc='count'))\n",
    "\n",
    "\n",
    "# remove ../data/TBX11K/imgs/ from the path column\n",
    "da_db['path'] = da_db['path'].apply(lambda x: x.replace(\"../data/TBX11K/imgs/\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n",
      "Counter({2: 103, 0: 97})\n",
      "Counter({0: 105, 2: 95})\n",
      "(400, 3)\n",
      "split\n",
      "train    200\n",
      "test     200\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    202\n",
      "2    198\n",
      "Name: count, dtype: int64\n",
      "label    0    2\n",
      "split          \n",
      "test   105   95\n",
      "train   97  103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mc_shenzhen_train = glob.glob(\"../data/TBX11K/imgs/extra/mc+shenzhen/train/*\")\n",
    "mc_shenzhen_test = glob.glob(\"../data/TBX11K/imgs/extra/mc+shenzhen/val/*\")\n",
    "\n",
    "print(len(mc_shenzhen_train), len(mc_shenzhen_test))\n",
    "\n",
    "def get_label(path):\n",
    "    #CXRs with  filename having \"_0\" are TB negative and  with \"_1\" are TB positive.\n",
    "    # path = only filename no extension\n",
    "    filename = os.path.basename(path).split(\".\")[0]\n",
    "    if filename.endswith(\"_0\"):\n",
    "        return 0\n",
    "    elif filename.endswith(\"_1\"):\n",
    "        return 2\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "mc_shenzhen_train_labels = [get_label(path) for path in mc_shenzhen_train]\n",
    "mc_shenzhen_test_labels = [get_label(path) for path in mc_shenzhen_test]\n",
    "\n",
    "print(Counter(mc_shenzhen_train_labels))\n",
    "print(Counter(mc_shenzhen_test_labels))\n",
    "\n",
    "mc_shenzhen_train_df = pd.DataFrame({'path': mc_shenzhen_train, 'label': mc_shenzhen_train_labels})\n",
    "mc_shenzhen_test_df = pd.DataFrame({'path': mc_shenzhen_test, 'label': mc_shenzhen_test_labels})\n",
    "\n",
    "mc_shenzhen_train_df['split'] = 'train'\n",
    "mc_shenzhen_test_df['split'] = 'test'\n",
    "\n",
    "mc_shenzhen = pd.concat([mc_shenzhen_train_df, mc_shenzhen_test_df])\n",
    "print(mc_shenzhen.shape)\n",
    "print(mc_shenzhen.split.value_counts())\n",
    "print(mc_shenzhen.label.value_counts())\n",
    "print(mc_shenzhen.pivot_table(index='split', columns='label', values='path', aggfunc='count'))\n",
    "\n",
    "# remove ../data/TBX11K/imgs/ from the path column\n",
    "mc_shenzhen['path'] = mc_shenzhen['path'].apply(lambda x: x.replace(\"../data/TBX11K/imgs/\", \"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source  da_db  mc_shenzhen  tbx11k\n",
      "split                             \n",
      "test       88          200    1800\n",
      "train      88          200    6600\n",
      "label     0     1    2\n",
      "split                 \n",
      "test    953   800  335\n",
      "train  3151  3000  737\n"
     ]
    }
   ],
   "source": [
    "# now combine all the dataframes\n",
    "\n",
    "mc_shenzhen['source'] = 'mc_shenzhen'\n",
    "da_db['source'] = 'da_db'\n",
    "tbx11k['source'] = 'tbx11k'\n",
    "\n",
    "tbx11k_merged = pd.concat([ tbx11k, mc_shenzhen, da_db])\n",
    "# tbx11k_merged.to_csv(\"../data/TBX11K/tbx11k-merged.csv\", index=False, header=True, sep=\"\\t\")\n",
    "\n",
    "print(tbx11k_merged.pivot_table(index='split', columns='source', values='path', aggfunc='count'))\n",
    "print(tbx11k_merged.pivot_table(index='split', columns='label', values='path', aggfunc='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images: 100%|| 8976/8976 [00:09<00:00, 969.80image/s] \n"
     ]
    }
   ],
   "source": [
    "# images = glob.glob(\"../data/TBX11K/imgs/*\")\n",
    "images = tbx11k_merged.path.to_list()\n",
    "add_path = \"../data/TBX11K/imgs/\"\n",
    "images = [add_path + image for image in images]\n",
    "\n",
    "\n",
    "def resize_image(input_path):\n",
    "    try:\n",
    "        with Image.open(input_path) as img:\n",
    "            img = img.resize((224, 224), Image.BICUBIC)\n",
    "            # Convert to RGB mode for all images\n",
    "            img = img.convert('RGB')\n",
    "            # Convert to jpg if not already jpg/jpeg\n",
    "            if not (input_path.lower().endswith('.jpg') or input_path.lower().endswith('.jpeg')):\n",
    "                output_path = os.path.splitext(input_path)[0] + '.jpg'\n",
    "                img.save(output_path, 'JPEG')  # Save as jpg\n",
    "                os.remove(input_path)  # Remove original file\n",
    "            else:\n",
    "                img.save(input_path)  # Overwrite original jpg/jpeg\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_path}: {e}\")\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "with Pool(processes=num_workers) as pool:\n",
    "    list(tqdm(\n",
    "        pool.imap(resize_image, images),\n",
    "        total=len(images),\n",
    "        desc=\"Resizing images\",\n",
    "        unit=\"image\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.jpg', '.png'}\n",
      "Counter({'.png': 8400, '.jpg': 576})\n",
      "{'.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# find all the extensions in tbx11k_merged\n",
    "print(set([os.path.splitext(image)[1] for image in tbx11k_merged['path'].to_list()]))\n",
    "print(Counter([os.path.splitext(image)[1] for image in tbx11k_merged['path'].to_list()]))\n",
    "\n",
    "# replace all the extensions with .jpg\n",
    "tbx11k_merged['path'] = tbx11k_merged['path'].apply(lambda x: os.path.splitext(x)[0] + '.jpg')\n",
    "\n",
    "# find all the extensions in tbx11k_merged\n",
    "print(set([os.path.splitext(image)[1] for image in tbx11k_merged['path'].to_list()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbx11k_merged.drop(columns=['source'], inplace=True)\n",
    "tbx11k_merged.to_csv(\"../data/TBX11K/tbx11k-merged.csv\", index=False, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSNA Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['patientId', 'class'], dtype='object')\n",
      "class\n",
      "No Lung Opacity / Not Normal    11821\n",
      "Lung Opacity                     9555\n",
      "Normal                           8851\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "1    11821\n",
      "2     9555\n",
      "0     8851\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId  class\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6      1\n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd      1\n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb      1\n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5      0\n",
       "4  00436515-870c-4b36-a041-de91049b9ab4      2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"../data/RSNA-Pneumonia/stage_2_detailed_class_info.csv\")\n",
    "print(labels.columns)\n",
    "print(labels['class'].value_counts())\n",
    "\n",
    "# replace No Lung Opacity / Not Normal with 1, Normal with 0, and Lung Opacity with 2\n",
    "labels['class'] = labels['class'].apply(lambda x: 1 if x == \"No Lung Opacity / Not Normal\" else 0 if x == \"Normal\" else 2 if x == \"Lung Opacity\" else None)\n",
    "print(labels['class'].value_counts())\n",
    "\n",
    "labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26684\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../data/RSNA-Pneumonia/stage_2_train_images/*\")\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/RSNA-Pneumonia/stage_2_train_images/60ae6dde-b322-4c93-ad89-1b061fa48098.dcm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|| 26684/26684 [04:04<00:00, 109.25image/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import cv2\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def resize_image(input_path, output_path, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize an image using PIL's BICUBIC interpolation.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input image or a PIL Image object\n",
    "        output_path: Path to save the resized image\n",
    "        size: Tuple of (width, height) for the output image\n",
    "    \"\"\"\n",
    "    with Image.open(input_path) as img:\n",
    "        img = img.resize(size, Image.BICUBIC)\n",
    "        img = img.convert('RGB')  # Ensure the image is in RGB mode\n",
    "        img.save(output_path, 'JPEG')\n",
    "\n",
    "def convert_dicom_to_cv2(dcm_file, temp_jpg_path):\n",
    "    \"\"\"\n",
    "    Convert a DICOM file to a CV2 image and save it as a JPEG.\n",
    "    \n",
    "    Args:\n",
    "        dcm_file: A file-like object containing DICOM data\n",
    "        temp_jpg_path: Path to save the temporary JPEG image\n",
    "    \"\"\"\n",
    "    dcm = pydicom.dcmread(dcm_file)\n",
    "    rescaled_image = cv2.convertScaleAbs(dcm.pixel_array, alpha=(255.0 / dcm.pixel_array.max()))\n",
    "\n",
    "    # Handle MONOCHROME1\n",
    "    if dcm.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        rescaled_image = cv2.bitwise_not(rescaled_image)\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    adjusted_image = cv2.equalizeHist(rescaled_image)\n",
    "\n",
    "    # Save the adjusted image as a temporary JPEG\n",
    "    cv2.imwrite(temp_jpg_path, adjusted_image)\n",
    "\n",
    "def process_single_file(args):\n",
    "    \"\"\"\n",
    "    Process a single DICOM file.\n",
    "    \n",
    "    Args:\n",
    "        args: Tuple of (dicom_path, output_dir, size)\n",
    "    \"\"\"\n",
    "    dicom_path, output_dir, size = args\n",
    "    try:\n",
    "        # Create output paths\n",
    "        filename = os.path.basename(dicom_path)\n",
    "        jpg_path = os.path.join(output_dir, filename.replace('.dcm', '.jpg'))\n",
    "        temp_jpg_path = os.path.join(output_dir, 'temp', filename.replace('.dcm', '.jpg'))\n",
    "        \n",
    "        # Convert DICOM to CV2 Image and save as temporary JPEG\n",
    "        convert_dicom_to_cv2(dicom_path, temp_jpg_path)\n",
    "        \n",
    "        # Resize using PIL and replace the original JPEG\n",
    "        resize_image(temp_jpg_path, jpg_path, size=size)\n",
    "        \n",
    "        # Remove the temporary JPEG file\n",
    "        os.remove(temp_jpg_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "def process_all_files(images, output_dir, size=(224, 224)):\n",
    "    with Pool(processes=8) as pool:\n",
    "        list(tqdm(\n",
    "            pool.imap(process_single_file, [(image, output_dir, size) for image in images]),\n",
    "            total=len(images),\n",
    "            desc=\"Processing images\",\n",
    "            unit=\"image\"\n",
    "        ))\n",
    "        \n",
    "os.makedirs(\"../data/RSNA-Pneumonia/stage_2_train_images_resized\", exist_ok=True)\n",
    "os.makedirs(\"../data/RSNA-Pneumonia/stage_2_train_images_resized/temp\", exist_ok=True)\n",
    "process_all_files(images, \"../data/RSNA-Pneumonia/stage_2_train_images_resized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/RSNA-Pneumonia/stage_2_train_images_resized/43605721-d0e0-4d58-b212-b05a295b21be.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob.glob(\"../data/RSNA-Pneumonia/stage_2_train_images_resized/*\")\n",
    "print(len(images))\n",
    "images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "# print the size of the first image\n",
    "print(Image.open(images[0]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    10591\n",
      "2     8633\n",
      "0     7980\n",
      "Name: count, dtype: int64 label\n",
      "1    1230\n",
      "2     922\n",
      "0     871\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels.rename(columns={'patientId': 'path', 'class': 'label'}, inplace=True)\n",
    "\n",
    "train, test = train_test_split(labels, test_size=0.1, random_state=42)\n",
    "\n",
    "print(train.label.value_counts(), test.label.value_counts())\n",
    "\n",
    "train['split'] = 'train'\n",
    "test['split'] = 'test'\n",
    "\n",
    "combined = pd.concat([train, test])\n",
    "\n",
    "# add .jpg to the path\n",
    "combined['path'] = combined['path'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "combined.to_csv(\"../data/RSNA-Pneumonia/rsna-pneumonia-merged.csv\", index=False, header=True, sep=\"\\t\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIIM-Pneumothorax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/SIIM-Pneumothorax/dicom-images-train/1.2.276.0.7230010.3.1.2.8323329.31920.1517875157.501098/1.2.276.0.7230010.3.1.3.8323329.31920.1517875157.501097/1.2.276.0.7230010.3.1.4.8323329.31920.1517875157.501099.dcm\n",
      "10712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.276.0.7230010.3.1.4.8323329.31920.1517875157.501099'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = glob.glob(\"../data/SIIM-Pneumothorax/dicom-images-train/*/*/*\")\n",
    "print(train_images[0])\n",
    "train_image_ids = [\".\".join(os.path.basename(image).split(\".\")[:-1]) for image in train_images] # get only the filename from the path\n",
    "print(len(train_image_ids))\n",
    "train_image_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.276.0.7230010.3.1.4.8323329.6585.1517875199.37328'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = glob.glob(\"../data/SIIM-Pneumothorax/dicom-images-test/*/*/*\")\n",
    "test_image_ids = [\".\".join(os.path.basename(image).split(\".\")[:-1]) for image in test_images] # get only the filename from the path\n",
    "print(len(test_image_ids))\n",
    "test_image_ids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12089 12089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../data/SIIM-Pneumothorax/dicom-images-train/1.2.276.0.7230010.3.1.2.8323329.31920.1517875157.501098/1.2.276.0.7230010.3.1.3.8323329.31920.1517875157.501097/1.2.276.0.7230010.3.1.4.8323329.31920.1517875157.501099.dcm',\n",
       " '1.2.276.0.7230010.3.1.4.8323329.31920.1517875157.501099')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = train_images + test_images\n",
    "image_ids = train_image_ids + test_image_ids\n",
    "\n",
    "id_to_paths = {image_id: image for image_id, image in zip(image_ids, images)}\n",
    "\n",
    "print(len(images), len(image_ids))\n",
    "images[0], image_ids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    8296\n",
      "1    3286\n",
      "Name: count, dtype: int64\n",
      "(11582, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5597.151787518...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.12515.15178752...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.4904.151787518...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.32579.15178751...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.32579.15178751...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  label\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.5597.151787518...      0\n",
       "1  1.2.276.0.7230010.3.1.4.8323329.12515.15178752...      0\n",
       "2  1.2.276.0.7230010.3.1.4.8323329.4904.151787518...      1\n",
       "3  1.2.276.0.7230010.3.1.4.8323329.32579.15178751...      1\n",
       "4  1.2.276.0.7230010.3.1.4.8323329.32579.15178751...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"../data/SIIM-Pneumothorax/train-rle.csv\")\n",
    "labels = labels.rename(columns={' EncodedPixels': 'label'})\n",
    "\n",
    "# if label is -1, then convert to 0, else convert to 1\n",
    "labels['label'] = labels['label'].apply(lambda x: 0 if x == ' -1' else 1)\n",
    "print(labels['label'].value_counts())\n",
    "print(labels.shape)\n",
    "labels.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12089"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10712+1377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    9378\n",
      "1    3576\n",
      "Name: count, dtype: int64\n",
      "(12954, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.3678.151787517...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.4200.151787518...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.4862.151787518...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.12313.15178752...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.14214.15178752...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  label\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.3678.151787517...      1\n",
       "1  1.2.276.0.7230010.3.1.4.8323329.4200.151787518...      0\n",
       "2  1.2.276.0.7230010.3.1.4.8323329.4862.151787518...      1\n",
       "3  1.2.276.0.7230010.3.1.4.8323329.12313.15178752...      0\n",
       "4  1.2.276.0.7230010.3.1.4.8323329.14214.15178752...      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_2_train = pd.read_csv(\"../data/SIIM-Pneumothorax/stage_2_train.csv\")\n",
    "\n",
    "# rename columns\n",
    "stage_2_train.rename(columns={'EncodedPixels': 'label'}, inplace=True)\n",
    "\n",
    "# Drop Unnamed: 0\n",
    "stage_2_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# if label is -1, then convert to 0, else convert to 1\n",
    "stage_2_train['label'] = stage_2_train['label'].apply(lambda x: 0 if x == '-1' else 1)\n",
    "print(stage_2_train['label'].value_counts())\n",
    "print(stage_2_train.shape)\n",
    "stage_2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12954 - 11582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found = []\n",
    "for image_id in stage_2_train['ImageId'].to_list():\n",
    "    if image_id not in image_ids:\n",
    "        not_found.append(image_id)\n",
    "print(len(not_found))\n",
    "not_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1372\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check imageids that are in stage_2_train but not in labels \n",
    "\n",
    "x = set(stage_2_train['ImageId'].to_list()) - set(labels['ImageId'].to_list())\n",
    "y = set(labels['ImageId'].to_list()) - set(stage_2_train['ImageId'].to_list())\n",
    "print(len(x))\n",
    "print(len(y))\n",
    "# x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|| 12089/12089 [02:24<00:00, 83.42image/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import cv2\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def resize_image(input_path, output_path, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Resize an image using PIL's BICUBIC interpolation.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input image or a PIL Image object\n",
    "        output_path: Path to save the resized image\n",
    "        size: Tuple of (width, height) for the output image\n",
    "    \"\"\"\n",
    "    with Image.open(input_path) as img:\n",
    "        img = img.resize(size, Image.BICUBIC)\n",
    "        img = img.convert('RGB')  # Ensure the image is in RGB mode\n",
    "        img.save(output_path, 'JPEG')\n",
    "\n",
    "def convert_dicom_to_cv2(dcm_file, temp_jpg_path):\n",
    "    \"\"\"\n",
    "    Convert a DICOM file to a CV2 image and save it as a JPEG.\n",
    "    \n",
    "    Args:\n",
    "        dcm_file: A file-like object containing DICOM data\n",
    "        temp_jpg_path: Path to save the temporary JPEG image\n",
    "    \"\"\"\n",
    "    dcm = pydicom.dcmread(dcm_file)\n",
    "    rescaled_image = cv2.convertScaleAbs(dcm.pixel_array, alpha=(255.0 / dcm.pixel_array.max()))\n",
    "\n",
    "    # Handle MONOCHROME1\n",
    "    if dcm.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        rescaled_image = cv2.bitwise_not(rescaled_image)\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    adjusted_image = cv2.equalizeHist(rescaled_image)\n",
    "\n",
    "    # Save the adjusted image as a temporary JPEG\n",
    "    cv2.imwrite(temp_jpg_path, adjusted_image)\n",
    "\n",
    "def process_single_file(args):\n",
    "    \"\"\"\n",
    "    Process a single DICOM file.\n",
    "    \n",
    "    Args:\n",
    "        args: Tuple of (dicom_path, output_dir, size)\n",
    "    \"\"\"\n",
    "    dicom_path, output_dir, size = args\n",
    "    try:\n",
    "        # Create output paths\n",
    "        filename = os.path.basename(dicom_path)\n",
    "        jpg_path = os.path.join(output_dir, filename.replace('.dcm', '.jpg'))\n",
    "        temp_jpg_path = os.path.join(output_dir, 'temp', filename.replace('.dcm', '.jpg'))\n",
    "        \n",
    "        # Convert DICOM to CV2 Image and save as temporary JPEG\n",
    "        convert_dicom_to_cv2(dicom_path, temp_jpg_path)\n",
    "        \n",
    "        # Resize using PIL and replace the original JPEG\n",
    "        resize_image(temp_jpg_path, jpg_path, size=size)\n",
    "        \n",
    "        # Remove the temporary JPEG file\n",
    "        os.remove(temp_jpg_path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "def process_all_files(images, output_dir, size=(224, 224)):\n",
    "    with Pool(processes=8) as pool:\n",
    "        list(tqdm(\n",
    "            pool.imap(process_single_file, [(image, output_dir, size) for image in images]),\n",
    "            total=len(images),\n",
    "            desc=\"Processing images\",\n",
    "            unit=\"image\"\n",
    "        ))\n",
    "        \n",
    "os.makedirs(\"../data/SIIM-Pneumothorax/images\", exist_ok=True)\n",
    "os.makedirs(\"../data/SIIM-Pneumothorax/images/temp\", exist_ok=True)\n",
    "process_all_files(images, \"../data/SIIM-Pneumothorax/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_2_train.rename(columns={'ImageId': 'path'}, inplace=True)\n",
    "\n",
    "# add .jpg to path\n",
    "stage_2_train['path'] = stage_2_train['path'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "train, test = train_test_split(stage_2_train, test_size=0.1, random_state=42)\n",
    "\n",
    "train['split'] = 'train'\n",
    "test['split'] = 'test'\n",
    "\n",
    "combined = pd.concat([train, test])\n",
    "combined\n",
    "combined.to_csv(\"../data/SIIM-Pneumothorax/siim-pneumothorax-merged.csv\", index=False, header=True, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/SIIM-Pneumothorax/images/1.2.276.0.7230010.3.1.4.8323329.4434.1517875182.843610.jpg'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob.glob(\"../data/SIIM-Pneumothorax/images/*\")\n",
    "print(len(images))\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = stage_2_train['path'].to_list()\n",
    "add_path = \"../data/SIIM-Pneumothorax/images/\"\n",
    "paths = [add_path + path for path in paths]\n",
    "\n",
    "# check in images if all the paths are present\n",
    "for path in paths:\n",
    "    if path not in images:\n",
    "        print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VinDR-CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'Aortic enlargement', 'Atelectasis', 'Calcification',\n",
      "       'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema',\n",
      "       'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity',\n",
      "       'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass',\n",
      "       'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
      "       'Pulmonary fibrosis', 'Rib fracture', 'COPD', 'Lung tumor', 'Pneumonia',\n",
      "       'Tuberculosis', 'No finding', 'split'],\n",
      "      dtype='object')\n",
      "Index(['image_id', 'Aortic enlargement', 'Atelectasis', 'Calcification',\n",
      "       'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema',\n",
      "       'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity',\n",
      "       'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass',\n",
      "       'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
      "       'Pulmonary fibrosis', 'Rib fracture', 'COPD', 'Lung tumor', 'Pneumonia',\n",
      "       'Tuberculosis', 'No finding', 'split'],\n",
      "      dtype='object')\n",
      "Index(['path', 'Aortic enlargement', 'Atelectasis', 'Calcification',\n",
      "       'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema',\n",
      "       'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity',\n",
      "       'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass',\n",
      "       'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
      "       'Pulmonary fibrosis', 'Rib fracture', 'COPD', 'Lung tumor', 'Pneumonia',\n",
      "       'Tuberculosis', 'No finding', 'split'],\n",
      "      dtype='object')\n",
      "(45000, 28) (3000, 28) (48000, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>Aortic enlargement</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Clavicle fracture</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Enlarged PA</th>\n",
       "      <th>...</th>\n",
       "      <th>Pleural thickening</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pulmonary fibrosis</th>\n",
       "      <th>Rib fracture</th>\n",
       "      <th>COPD</th>\n",
       "      <th>Lung tumor</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Tuberculosis</th>\n",
       "      <th>No finding</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00053190460d56c53cc3e57321387478.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00053190460d56c53cc3e57321387478.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   path  Aortic enlargement  Atelectasis  \\\n",
       "0  000434271f63a053c4128a0ba6352c7f.jpg                   0            0   \n",
       "1  000434271f63a053c4128a0ba6352c7f.jpg                   0            0   \n",
       "2  000434271f63a053c4128a0ba6352c7f.jpg                   0            0   \n",
       "3  00053190460d56c53cc3e57321387478.jpg                   0            0   \n",
       "4  00053190460d56c53cc3e57321387478.jpg                   0            0   \n",
       "\n",
       "   Calcification  Cardiomegaly  Clavicle fracture  Consolidation  Edema  \\\n",
       "0              0             0                  0              0      0   \n",
       "1              0             0                  0              0      0   \n",
       "2              0             0                  0              0      0   \n",
       "3              0             0                  0              0      0   \n",
       "4              0             0                  0              0      0   \n",
       "\n",
       "   Emphysema  Enlarged PA  ...  Pleural thickening  Pneumothorax  \\\n",
       "0          0            0  ...                   0             0   \n",
       "1          0            0  ...                   0             0   \n",
       "2          0            0  ...                   0             0   \n",
       "3          0            0  ...                   0             0   \n",
       "4          0            0  ...                   0             0   \n",
       "\n",
       "   Pulmonary fibrosis  Rib fracture  COPD  Lung tumor  Pneumonia  \\\n",
       "0                   0             0     0           0          0   \n",
       "1                   0             0     0           0          0   \n",
       "2                   0             0     0           0          0   \n",
       "3                   0             0     0           0          0   \n",
       "4                   0             0     0           0          0   \n",
       "\n",
       "   Tuberculosis  No finding  split  \n",
       "0             0           1  train  \n",
       "1             0           1  train  \n",
       "2             0           1  train  \n",
       "3             0           1  train  \n",
       "4             0           1  train  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(\"../data/VinDr-CXR/image_labels_train.csv\")\n",
    "test_labels = pd.read_csv(\"../data/VinDr-CXR/image_labels_test.csv\")\n",
    "\n",
    "train_labels['split'] = 'train'\n",
    "test_labels['split'] = 'test'\n",
    "\n",
    "drop_columns = ['rad_id', 'Other diseases', 'Other lesion']\n",
    "train_labels.drop(columns=drop_columns, inplace=True)\n",
    "drop_columns = [ 'Other disease', 'Other lesion']\n",
    "test_labels.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "\n",
    "combined = pd.concat([train_labels, test_labels])\n",
    "combined.rename(columns={'image_id': 'path'}, inplace=True)\n",
    "combined['path'] = combined['path'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "print(train_labels.columns)\n",
    "print(test_labels.columns)\n",
    "print(combined.columns)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape, combined.shape)\n",
    "\n",
    "train_labels.head()\n",
    "test_labels.head()\n",
    "combined.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"../data/VinDr-CXR/vin-dr-cxr-merged.csv\", index=False, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../data/VinDr-CXR/images/*/*.jpg\")\n",
    "print(len(images))\n",
    "images[0]\n",
    "\n",
    "# remove ../data/VinDr-CXR/images/test/ and ../data/VinDr-CXR/images/train from the paths to create image_ids\n",
    "image_ids = [os.path.basename(image).split(\".\")[0] for image in images]\n",
    "print(len(image_ids))\n",
    "image_ids[0]\n",
    "\n",
    "image_ids_to_paths = {image_id: image for image_id, image in zip(image_ids, images)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_paths = combined['path'].to_list()\n",
    "\n",
    "\n",
    "# remove .jpg from the end of the paths\n",
    "combined_paths = [path.replace('.jpg', '') for path in combined_paths]\n",
    "\n",
    "# check if all the paths are present in image_ids_to_paths\n",
    "for path in combined_paths:\n",
    "    if path not in image_ids_to_paths:\n",
    "        print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 18000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_ids), len(set(image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 18000/18000 [00:02<00:00, 8312.54it/s] \n"
     ]
    }
   ],
   "source": [
    "# copy all the images from the train and test folders to a single folder\n",
    "os.makedirs(\"../data/VinDr-CXR/images_eval\", exist_ok=True)\n",
    "for path in tqdm(images):\n",
    "    shutil.copy(path, \"../data/VinDr-CXR/images_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column sums:\n",
      "Aortic enlargement: 7188, 220\n",
      "Atelectasis: 267, 86\n",
      "Calcification: 692, 194\n",
      "Cardiomegaly: 5430, 309\n",
      "Clavicle fracture: 29, 2\n",
      "Consolidation: 505, 96\n",
      "Edema: 14, 0\n",
      "Emphysema: 101, 3\n",
      "Enlarged PA: 156, 8\n",
      "ILD: 620, 221\n",
      "Infiltration: 949, 58\n",
      "Lung Opacity: 2045, 84\n",
      "Lung cavity: 80, 9\n",
      "Lung cyst: 38, 2\n",
      "Mediastinal shift: 270, 20\n",
      "Nodule/Mass: 1431, 176\n",
      "Pleural effusion: 2111, 111\n",
      "Pleural thickening: 3257, 169\n",
      "Pneumothorax: 199, 18\n",
      "Pulmonary fibrosis: 3271, 217\n",
      "Rib fracture: 150, 11\n",
      "COPD: 46, 2\n",
      "Lung tumor: 478, 80\n",
      "Pneumonia: 1570, 246\n",
      "Tuberculosis: 1479, 164\n",
      "No finding: 31685, 2051\n",
      "\n",
      "Percentage of positive labels:\n",
      "Aortic enlargement: 0.1597, 0.0733\n",
      "Atelectasis: 0.0059, 0.0287\n",
      "Calcification: 0.0154, 0.0647\n",
      "Cardiomegaly: 0.1207, 0.1030\n",
      "Clavicle fracture: 0.0006, 0.0007\n",
      "Consolidation: 0.0112, 0.0320\n",
      "Edema: 0.0003, 0.0000\n",
      "Emphysema: 0.0022, 0.0010\n",
      "Enlarged PA: 0.0035, 0.0027\n",
      "ILD: 0.0138, 0.0737\n",
      "Infiltration: 0.0211, 0.0193\n",
      "Lung Opacity: 0.0454, 0.0280\n",
      "Lung cavity: 0.0018, 0.0030\n",
      "Lung cyst: 0.0008, 0.0007\n",
      "Mediastinal shift: 0.0060, 0.0067\n",
      "Nodule/Mass: 0.0318, 0.0587\n",
      "Pleural effusion: 0.0469, 0.0370\n",
      "Pleural thickening: 0.0724, 0.0563\n",
      "Pneumothorax: 0.0044, 0.0060\n",
      "Pulmonary fibrosis: 0.0727, 0.0723\n",
      "Rib fracture: 0.0033, 0.0037\n",
      "COPD: 0.0010, 0.0007\n",
      "Lung tumor: 0.0106, 0.0267\n",
      "Pneumonia: 0.0349, 0.0820\n",
      "Tuberculosis: 0.0329, 0.0547\n",
      "No finding: 0.7041, 0.6837\n"
     ]
    }
   ],
   "source": [
    "labels = ['Aortic enlargement', 'Atelectasis', 'Calcification',\n",
    "       'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema',\n",
    "       'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity',\n",
    "       'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass',\n",
    "       'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
    "       'Pulmonary fibrosis', 'Rib fracture', 'COPD', 'Lung tumor', 'Pneumonia',\n",
    "       'Tuberculosis', 'No finding']\n",
    "\n",
    "#print column sums and percentage of positive labels in both train and test separately\n",
    "print(\"Column sums:\")\n",
    "for label in labels:\n",
    "    print(f\"{label}: {train_labels[label].sum()}, {test_labels[label].sum()}\")\n",
    "\n",
    "print(\"\\nPercentage of positive labels:\")\n",
    "for label in labels:\n",
    "    print(f\"{label}: {train_labels[label].sum() / len(train_labels):.4f}, {test_labels[label].sum() / len(test_labels):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VinDr-PCXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'rad_ID', 'No finding', 'Bronchitis', 'Brocho-pneumonia',\n",
      "       'Other disease', 'Bronchiolitis', 'Situs inversus', 'Pneumonia',\n",
      "       'Pleuro-pneumonia', 'Diagphramatic hernia', 'Tuberculosis',\n",
      "       'Congenital emphysema', 'CPAM', 'Hyaline membrane disease',\n",
      "       'Mediastinal tumor', 'Lung tumor', 'split'],\n",
      "      dtype='object')\n",
      "Index(['image_id', 'rad_ID', 'No finding', 'Bronchitis', 'Brocho-pneumonia',\n",
      "       'Other disease', 'Bronchiolitis', 'Situs inversus', 'Pneumonia',\n",
      "       'Pleuro-pneumonia', 'Diagphramatic hernia', 'Tuberculosis',\n",
      "       'Congenital emphysema', 'CPAM', 'Hyaline membrane disease',\n",
      "       'Mediastinal tumor', 'Lung tumor', 'split'],\n",
      "      dtype='object')\n",
      "Index(['path', 'No finding', 'Bronchitis', 'Brocho-pneumonia', 'Bronchiolitis',\n",
      "       'Situs inversus', 'Pneumonia', 'Pleuro-pneumonia',\n",
      "       'Diagphramatic hernia', 'Tuberculosis', 'Congenital emphysema', 'CPAM',\n",
      "       'Hyaline membrane disease', 'Mediastinal tumor', 'Lung tumor', 'split'],\n",
      "      dtype='object')\n",
      "(7728, 18) (1397, 18) (9125, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>No finding</th>\n",
       "      <th>Bronchitis</th>\n",
       "      <th>Brocho-pneumonia</th>\n",
       "      <th>Bronchiolitis</th>\n",
       "      <th>Situs inversus</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleuro-pneumonia</th>\n",
       "      <th>Diagphramatic hernia</th>\n",
       "      <th>Tuberculosis</th>\n",
       "      <th>Congenital emphysema</th>\n",
       "      <th>CPAM</th>\n",
       "      <th>Hyaline membrane disease</th>\n",
       "      <th>Mediastinal tumor</th>\n",
       "      <th>Lung tumor</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6cb53aff85c71b98ad13d67a131708c6.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40414c05687cdb156823c156967b13f0.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e4a464dfbf8abc6333c82f1b77b6455.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4d3fab0b71381e6b237dc36301e85a0.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b58c9b1c89978a0b1f8533b7a2ca1088.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   path  No finding  Bronchitis  \\\n",
       "0  6cb53aff85c71b98ad13d67a131708c6.jpg         0.0         0.0   \n",
       "1  40414c05687cdb156823c156967b13f0.jpg         0.0         0.0   \n",
       "2  0e4a464dfbf8abc6333c82f1b77b6455.jpg         0.0         0.0   \n",
       "3  f4d3fab0b71381e6b237dc36301e85a0.jpg         0.0         0.0   \n",
       "4  b58c9b1c89978a0b1f8533b7a2ca1088.jpg         0.0         0.0   \n",
       "\n",
       "   Brocho-pneumonia  Bronchiolitis  Situs inversus  Pneumonia  \\\n",
       "0               0.0            0.0             0.0        1.0   \n",
       "1               0.0            1.0             0.0        0.0   \n",
       "2               0.0            1.0             0.0        0.0   \n",
       "3               0.0            1.0             0.0        0.0   \n",
       "4               0.0            0.0             0.0        0.0   \n",
       "\n",
       "   Pleuro-pneumonia  Diagphramatic hernia  Tuberculosis  Congenital emphysema  \\\n",
       "0               0.0                   0.0           0.0                   0.0   \n",
       "1               0.0                   0.0           0.0                   0.0   \n",
       "2               0.0                   0.0           0.0                   0.0   \n",
       "3               0.0                   0.0           0.0                   0.0   \n",
       "4               0.0                   0.0           0.0                   0.0   \n",
       "\n",
       "   CPAM  Hyaline membrane disease  Mediastinal tumor  Lung tumor  split  \n",
       "0   0.0                       0.0                0.0         0.0  train  \n",
       "1   0.0                       0.0                0.0         0.0  train  \n",
       "2   0.0                       0.0                0.0         0.0  train  \n",
       "3   0.0                       0.0                0.0         0.0  train  \n",
       "4   0.0                       0.0                0.0         0.0  train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same as above for VinDr-PCXR\n",
    "\n",
    "train_labels = pd.read_csv(\"../data/VinDr-PCXR/image_labels_train.csv\")\n",
    "test_labels = pd.read_csv(\"../data/VinDr-PCXR/image_labels_test.csv\")\n",
    "train_labels['split'] = 'train'\n",
    "test_labels['split'] = 'test'\n",
    "\n",
    "combined = pd.concat([train_labels, test_labels])\n",
    "combined.rename(columns={'image_id': 'path'}, inplace=True)\n",
    "combined['path'] = combined['path'].apply(lambda x: x + '.jpg')\n",
    "combined.drop(columns=['rad_ID', 'Other disease'], inplace=True)\n",
    "\n",
    "print(train_labels.columns)\n",
    "print(test_labels.columns)\n",
    "print(combined.columns)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape, combined.shape)\n",
    "\n",
    "train_labels.head()\n",
    "test_labels.head()\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9123\n",
      "9123\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../data/VinDr-PCXR/images/*/*.jpg\")\n",
    "print(len(images))\n",
    "images[0]\n",
    "\n",
    "image_ids = [os.path.basename(image).split(\".\")[0] for image in images]\n",
    "print(len(image_ids))\n",
    "image_ids[0]\n",
    "\n",
    "image_ids_to_paths = {image_id: image for image_id, image in zip(image_ids, images)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9125\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "combined_paths = combined['path'].to_list()\n",
    "print(len(combined_paths))\n",
    "combined_paths = [path.replace('.jpg', '') for path in combined_paths]\n",
    "\n",
    "# check if all the paths are present in image_ids_to_paths\n",
    "not_found = []\n",
    "for path in combined_paths:\n",
    "    if path not in image_ids:\n",
    "        not_found.append(path)\n",
    "print(len(not_found))\n",
    "# len(image_ids), len(set(image_ids))\n",
    "not_found = [path+'.jpg' for path in not_found]\n",
    "# Drop the rows in combined where path is in not_found\n",
    "combined = combined[~combined['path'].isin(not_found)]\n",
    "combined\n",
    "combined.to_csv(\"../data/VinDr-PCXR/vin-dr-pcxr-merged.csv\", index=False, header=True, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 9123/9123 [00:00<00:00, 11201.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# copy all the images from the train and test folders to a single folder\n",
    "os.makedirs(\"../data/VinDr-PCXR/images_eval\", exist_ok=True)\n",
    "for path in tqdm(images):\n",
    "    shutil.copy(path, \"../data/VinDr-PCXR/images_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column sums:\n",
      "No finding: 5143.0, 907.0\n",
      "Bronchitis: 842.0, 174.0\n",
      "Brocho-pneumonia: 545.0, 84.0\n",
      "Bronchiolitis: 497.0, 90.0\n",
      "Situs inversus: 11.0, 2.0\n",
      "Pneumonia: 392.0, 89.0\n",
      "Pleuro-pneumonia: 6.0, 0.0\n",
      "Diagphramatic hernia: 3.0, 0.0\n",
      "Tuberculosis: 14.0, 1.0\n",
      "Congenital emphysema: 2.0, 0.0\n",
      "CPAM: 5.0, 1.0\n",
      "Hyaline membrane disease: 19.0, 3.0\n",
      "Mediastinal tumor: 8.0, 1.0\n",
      "Lung tumor: 5.0, 0.0\n",
      "\n",
      "Percentage of positive labels:\n",
      "No finding: 0.6655, 0.6492\n",
      "Bronchitis: 0.1090, 0.1246\n",
      "Brocho-pneumonia: 0.0705, 0.0601\n",
      "Bronchiolitis: 0.0643, 0.0644\n",
      "Situs inversus: 0.0014, 0.0014\n",
      "Pneumonia: 0.0507, 0.0637\n",
      "Pleuro-pneumonia: 0.0008, 0.0000\n",
      "Diagphramatic hernia: 0.0004, 0.0000\n",
      "Tuberculosis: 0.0018, 0.0007\n",
      "Congenital emphysema: 0.0003, 0.0000\n",
      "CPAM: 0.0006, 0.0007\n",
      "Hyaline membrane disease: 0.0025, 0.0021\n",
      "Mediastinal tumor: 0.0010, 0.0007\n",
      "Lung tumor: 0.0006, 0.0000\n"
     ]
    }
   ],
   "source": [
    "labels = ['No finding', 'Bronchitis', 'Brocho-pneumonia', 'Bronchiolitis',\n",
    "       'Situs inversus', 'Pneumonia', 'Pleuro-pneumonia',\n",
    "       'Diagphramatic hernia', 'Tuberculosis', 'Congenital emphysema', 'CPAM',\n",
    "       'Hyaline membrane disease', 'Mediastinal tumor', 'Lung tumor']\n",
    "\n",
    "#print column sums and percentage of positive labels in both train and test separately\n",
    "print(\"Column sums:\")\n",
    "for label in labels:\n",
    "    print(f\"{label}: {train_labels[label].sum()}, {test_labels[label].sum()}\")\n",
    "\n",
    "print(\"\\nPercentage of positive labels:\")\n",
    "for label in labels:\n",
    "    print(f\"{label}: {train_labels[label].sum() / len(train_labels):.4f}, {test_labels[label].sum() / len(test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
