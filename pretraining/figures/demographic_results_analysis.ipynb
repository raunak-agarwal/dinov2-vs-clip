{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions.csv\t\t      mimic-cxr-2.0.0-split.csv\n",
      "clip-files\t\t      mimic-cxr-2.1.0-test-set-labeled.csv\n",
      "final-datasets\t\t      mimic_cxr_labels_reports_splits.csv\n",
      "IMAGE_FILENAMES\t\t      mimic-cxr-lt\n",
      "images\t\t\t      mimic_cxr_sectioned.csv\n",
      "LICENSE.txt\t\t      mimic_cxr_sections.csv\n",
      "mimic-cxr-2.0.0-chexpert.csv  patients.csv\n",
      "mimic-cxr-2.0.0-merged.csv    README\n",
      "mimic-cxr-2.0.0-metadata.csv  reports\n",
      "mimic-cxr-2.0.0-negbio.csv    resize_mimic.py\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'race'], dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MIMIC Demographic Robustness\n",
    "\n",
    "\n",
    "admissions = pd.read_csv(\"../../data/MIMIC-CXR/mimic-cxr-jpg-2.0.0-small/admissions.csv\", sep=\",\")[['subject_id','race']]\n",
    "admissions['subject_id'] = admissions['subject_id'].astype(int)\n",
    "admissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_simplified\n",
      "White                  362601\n",
      "Black                   89057\n",
      "Other                   39894\n",
      "Hispanic/Latino         32984\n",
      "East Asian              16117\n",
      "South East Asian         1973\n",
      "Indian                   1661\n",
      "Indigenous American      1247\n",
      "Pacific Islander          494\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary for race categories\n",
    "race_mapping = {\n",
    "    # White/European categories\n",
    "    'WHITE': 'White',\n",
    "    'WHITE - OTHER EUROPEAN': 'White',\n",
    "    'WHITE - RUSSIAN': 'White',\n",
    "    'WHITE - EASTERN EUROPEAN': 'White',\n",
    "    'WHITE - BRAZILIAN': 'White',\n",
    "    'PORTUGUESE': 'White',\n",
    "    \n",
    "    # Black categories\n",
    "    'BLACK/AFRICAN AMERICAN': 'Black',\n",
    "    'BLACK/CAPE VERDEAN': 'Black',\n",
    "    'BLACK/CARIBBEAN ISLAND': 'Black',\n",
    "    'BLACK/AFRICAN': 'Black',\n",
    "    \n",
    "    # Asian categories\n",
    "    'ASIAN': 'East Asian',\n",
    "    'ASIAN - CHINESE': 'East Asian',\n",
    "    'ASIAN - SOUTH EAST ASIAN': 'South East Asian',\n",
    "    'ASIAN - ASIAN INDIAN': 'Indian',\n",
    "    'ASIAN - KOREAN': 'East Asian',\n",
    "    \n",
    "    # Hispanic/Latino categories\n",
    "    'HISPANIC/LATINO - PUERTO RICAN': 'Hispanic/Latino',\n",
    "    'HISPANIC OR LATINO': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - DOMINICAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - GUATEMALAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - SALVADORAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - COLUMBIAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - MEXICAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - HONDURAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - CUBAN': 'Hispanic/Latino',\n",
    "    'HISPANIC/LATINO - CENTRAL AMERICAN': 'Hispanic/Latino',\n",
    "    'SOUTH AMERICAN': 'Hispanic/Latino',\n",
    "    \n",
    "    # US American categories\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER': 'Pacific Islander',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE': 'Indigenous American',\n",
    "    \n",
    "    # Other categories\n",
    "    'OTHER': 'Other',\n",
    "    'MULTIPLE RACE/ETHNICITY': 'Other',\n",
    "    \n",
    "    # Unknown/Missing categories\n",
    "    'UNKNOWN': 'Other',\n",
    "    'UNABLE TO OBTAIN': 'Other',\n",
    "    'PATIENT DECLINED TO ANSWER': 'Other'\n",
    "}\n",
    "\n",
    "# Apply the mapping to create a new simplified race column\n",
    "admissions['race_simplified'] = admissions['race'].map(race_mapping)\n",
    "\n",
    "# View the simplified distribution\n",
    "print(admissions['race_simplified'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_from_path(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract subject ID from the file path.\n",
    "    \n",
    "    Args:\n",
    "        path: String containing the file path (e.g., mimic/files/p10/p10046166/s56173345/...)\n",
    "        \n",
    "    Returns:\n",
    "        Subject ID without 'p' prefix (e.g., '10046166')\n",
    "    \"\"\"\n",
    "    # Split the path and get the 4th component (index 3) which contains the full subject ID\n",
    "    return path.split('/')[3][1:]  # Remove the 'p' prefix\n",
    "\n",
    "def calculate_macro_auc(df, category_col, category_value):\n",
    "    mask = df[category_col] == category_value\n",
    "    category_data = df[mask]\n",
    "    \n",
    "    aucs = []\n",
    "    conditions = [col.replace('_pred', '') for col in df.columns if col.endswith('_pred')]\n",
    "    \n",
    "    for condition in conditions:\n",
    "        y_true = category_data[f'{condition}_true']\n",
    "        y_pred = category_data[f'{condition}_pred']\n",
    "        \n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_pred)\n",
    "            aucs.append(auc)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return np.mean(aucs) if aucs else np.nan\n",
    "\n",
    "def calculate_group_metrics(df, group_col, categories):\n",
    "    aucs = {}\n",
    "    for category in categories:\n",
    "        macro_auc = calculate_macro_auc(df, group_col, category)\n",
    "        aucs[category] = macro_auc\n",
    "        \n",
    "    results = pd.DataFrame({\n",
    "        'Macro AUC-ROC': aucs,\n",
    "        'Sample Size': df[group_col].value_counts()\n",
    "    }).round(3)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5159, 32)\n",
      "\n",
      "Macro AUC-ROC scores by race:\n",
      "                     Macro AUC-ROC  Sample Size\n",
      "White                        0.770         3411\n",
      "Black                        0.781         1026\n",
      "Hispanic/Latino              0.744          154\n",
      "Other                        0.751          123\n",
      "East Asian                   0.713           84\n",
      "Indian                       0.696           53\n",
      "South East Asian             0.624           17\n",
      "Indigenous American          0.735           14\n",
      "\n",
      "Macro AUC-ROC scores by sex:\n",
      "         Macro AUC-ROC  Sample Size\n",
      "M                0.762         2744\n",
      "F                0.781         2138\n",
      "unknown          0.734          277\n",
      "\n",
      "Macro AUC-ROC scores by age bin:\n",
      "       Macro AUC-ROC  Sample Size\n",
      "18-35          0.740           67\n",
      "36-50          0.806          426\n",
      "51-70          0.770         2772\n",
      "71+            0.762         1617\n"
     ]
    }
   ],
   "source": [
    "results_clip = pd.read_csv(\"../../results/mimic/clip-mimic-full-ft/test_predictions.csv\", sep=\",\")\n",
    "results_clip['subject_id'] = results_clip['path'].apply(lambda x: get_subject_from_path(x)).astype(int)\n",
    "print(results_clip.shape)\n",
    "# Merge the results with admissions data\n",
    "# Drop duplicates from admissions before merging to avoid multiplying rows\n",
    "results_clip = results_clip.merge(admissions[['subject_id', 'race_simplified']].drop_duplicates(subset=['subject_id']), on='subject_id', how='left')\n",
    "\n",
    "# Convert age to numeric, coercing errors to NaN\n",
    "results_clip['age'] = pd.to_numeric(results_clip['age'], errors='coerce')\n",
    "\n",
    "# Calculate for race\n",
    "races = ['White', 'Black', 'Hispanic/Latino', 'Other', 'East Asian', \n",
    "         'Indian', 'South East Asian', 'Indigenous American']\n",
    "race_results = calculate_group_metrics(results_clip, 'race_simplified', races)\n",
    "\n",
    "# Calculate for sex\n",
    "sexes = ['M', 'F', 'unknown']\n",
    "sex_results = calculate_group_metrics(results_clip, 'sex', sexes)\n",
    "\n",
    "# Create age bins with new ranges\n",
    "results_clip['age_bin'] = pd.cut(results_clip['age'], \n",
    "                                bins=[17, 35, 50, 70, 100],\n",
    "                                labels=['18-35', '36-50', '51-70', '71+'])\n",
    "age_results = calculate_group_metrics(results_clip, 'age_bin', \n",
    "                                    results_clip['age_bin'].dropna().unique())\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMacro AUC-ROC scores by race:\")\n",
    "print(race_results)\n",
    "print(\"\\nMacro AUC-ROC scores by sex:\")\n",
    "print(sex_results)\n",
    "print(\"\\nMacro AUC-ROC scores by age bin:\")\n",
    "print(age_results.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5159, 32)\n",
      "\n",
      "Macro AUC-ROC scores by race:\n",
      "                     Macro AUC-ROC  Sample Size\n",
      "White                        0.767         3411\n",
      "Black                        0.781         1026\n",
      "Hispanic/Latino              0.711          154\n",
      "Other                        0.741          123\n",
      "East Asian                   0.743           84\n",
      "Indian                       0.594           53\n",
      "South East Asian             0.499           17\n",
      "Indigenous American          0.795           14\n",
      "\n",
      "Macro AUC-ROC scores by sex:\n",
      "         Macro AUC-ROC  Sample Size\n",
      "M                0.763         2744\n",
      "F                0.777         2138\n",
      "unknown          0.719          277\n",
      "\n",
      "Macro AUC-ROC scores by age bin:\n",
      "       Macro AUC-ROC  Sample Size\n",
      "18-35          0.741           67\n",
      "36-50          0.800          426\n",
      "51-70          0.769         2772\n",
      "71+            0.757         1617\n"
     ]
    }
   ],
   "source": [
    "results_dino = pd.read_csv(\"../../results/mimic/dino-mimic-full-ft/test_predictions.csv\", sep=\",\")\n",
    "results_dino['subject_id'] = results_dino['path'].apply(lambda x: get_subject_from_path(x)).astype(int)\n",
    "print(results_dino.shape)\n",
    "# Merge the results with admissions data\n",
    "# Drop duplicates from admissions before merging to avoid multiplying rows\n",
    "results_dino = results_dino.merge(admissions[['subject_id', 'race_simplified']].drop_duplicates(subset=['subject_id']), on='subject_id', how='left')\n",
    "\n",
    "# Convert age to numeric, coercing errors to NaN\n",
    "results_dino['age'] = pd.to_numeric(results_dino['age'], errors='coerce')\n",
    "\n",
    "# Calculate for race\n",
    "races = ['White', 'Black', 'Hispanic/Latino', 'Other', 'East Asian', \n",
    "         'Indian', 'South East Asian', 'Indigenous American']\n",
    "race_results = calculate_group_metrics(results_dino, 'race_simplified', races)\n",
    "\n",
    "# Calculate for sex\n",
    "sexes = ['M', 'F', 'unknown']\n",
    "sex_results = calculate_group_metrics(results_dino, 'sex', sexes)\n",
    "\n",
    "# Create age bins with new ranges\n",
    "results_dino['age_bin'] = pd.cut(results_dino['age'], \n",
    "                                bins=[17, 35, 50, 70, 100],\n",
    "                                labels=['18-35', '36-50', '51-70', '71+'])\n",
    "age_results = calculate_group_metrics(results_dino, 'age_bin', \n",
    "                                    results_dino['age_bin'].dropna().unique())\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMacro AUC-ROC scores by race:\")\n",
    "print(race_results)\n",
    "print(\"\\nMacro AUC-ROC scores by sex:\")\n",
    "print(sex_results)\n",
    "print(\"\\nMacro AUC-ROC scores by age bin:\")\n",
    "print(age_results.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>Effusion_pred</th>\n",
       "      <th>Effusion_true</th>\n",
       "      <th>Cardiomegaly_pred</th>\n",
       "      <th>Cardiomegaly_true</th>\n",
       "      <th>Hernia_pred</th>\n",
       "      <th>Hernia_true</th>\n",
       "      <th>Infiltration_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>Pneumothorax_pred</th>\n",
       "      <th>Pneumothorax_true</th>\n",
       "      <th>Consolidation_pred</th>\n",
       "      <th>Consolidation_true</th>\n",
       "      <th>Fibrosis_pred</th>\n",
       "      <th>Fibrosis_true</th>\n",
       "      <th>Atelectasis_pred</th>\n",
       "      <th>Atelectasis_true</th>\n",
       "      <th>Emphysema_pred</th>\n",
       "      <th>Emphysema_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nih/files/00000003_000.jpg</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.187914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035488</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nih/files/00000003_001.jpg</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>0.033695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nih/files/00000003_002.jpg</td>\n",
       "      <td>75</td>\n",
       "      <td>F</td>\n",
       "      <td>0.038123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nih/files/00000003_003.jpg</td>\n",
       "      <td>76</td>\n",
       "      <td>F</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.190932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nih/files/00000003_004.jpg</td>\n",
       "      <td>77</td>\n",
       "      <td>F</td>\n",
       "      <td>0.026186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25591</th>\n",
       "      <td>nih/files/00030800_000.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25592</th>\n",
       "      <td>nih/files/00030802_000.jpg</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25593</th>\n",
       "      <td>nih/files/00030803_000.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25594</th>\n",
       "      <td>nih/files/00030804_000.jpg</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25595</th>\n",
       "      <td>nih/files/00030805_000.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25596 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             path  age sex  Effusion_pred  Effusion_true  \\\n",
       "0      nih/files/00000003_000.jpg   81   F       0.006558            0.0   \n",
       "1      nih/files/00000003_001.jpg   74   F       0.033695            0.0   \n",
       "2      nih/files/00000003_002.jpg   75   F       0.038123            0.0   \n",
       "3      nih/files/00000003_003.jpg   76   F       0.007421            0.0   \n",
       "4      nih/files/00000003_004.jpg   77   F       0.026186            0.0   \n",
       "...                           ...  ...  ..            ...            ...   \n",
       "25591  nih/files/00030800_000.jpg   33   F       0.002021            0.0   \n",
       "25592  nih/files/00030802_000.jpg   28   M       0.008127            0.0   \n",
       "25593  nih/files/00030803_000.jpg   42   F       0.000445            0.0   \n",
       "25594  nih/files/00030804_000.jpg   29   F       0.001043            0.0   \n",
       "25595  nih/files/00030805_000.jpg   26   M       0.001244            0.0   \n",
       "\n",
       "       Cardiomegaly_pred  Cardiomegaly_true  Hernia_pred  Hernia_true  \\\n",
       "0               0.005496                0.0     0.261728          1.0   \n",
       "1               0.000766                0.0     0.021580          1.0   \n",
       "2               0.000563                0.0     0.010076          1.0   \n",
       "3               0.002291                0.0     0.197293          1.0   \n",
       "4               0.005705                0.0     0.136466          1.0   \n",
       "...                  ...                ...          ...          ...   \n",
       "25591           0.000814                0.0     0.000123          0.0   \n",
       "25592           0.000126                0.0     0.001026          0.0   \n",
       "25593           0.000232                0.0     0.000064          0.0   \n",
       "25594           0.001165                0.0     0.000260          0.0   \n",
       "25595           0.002698                0.0     0.000073          0.0   \n",
       "\n",
       "       Infiltration_pred  ...  Pneumothorax_pred  Pneumothorax_true  \\\n",
       "0               0.187914  ...           0.009401                0.0   \n",
       "1               0.072808  ...           0.009996                0.0   \n",
       "2               0.139784  ...           0.067669                0.0   \n",
       "3               0.190932  ...           0.006647                0.0   \n",
       "4               0.141375  ...           0.020259                0.0   \n",
       "...                  ...  ...                ...                ...   \n",
       "25591           0.069264  ...           0.001955                0.0   \n",
       "25592           0.024381  ...           0.000690                0.0   \n",
       "25593           0.026123  ...           0.005908                0.0   \n",
       "25594           0.012811  ...           0.000711                0.0   \n",
       "25595           0.022508  ...           0.001518                0.0   \n",
       "\n",
       "       Consolidation_pred  Consolidation_true  Fibrosis_pred  Fibrosis_true  \\\n",
       "0                0.016332                 0.0       0.049511            0.0   \n",
       "1                0.013031                 0.0       0.052587            0.0   \n",
       "2                0.019529                 0.0       0.028977            0.0   \n",
       "3                0.008383                 0.0       0.057987            0.0   \n",
       "4                0.012189                 0.0       0.116217            0.0   \n",
       "...                   ...                 ...            ...            ...   \n",
       "25591            0.001592                 0.0       0.003554            0.0   \n",
       "25592            0.003689                 0.0       0.026131            0.0   \n",
       "25593            0.001366                 0.0       0.001946            0.0   \n",
       "25594            0.000901                 0.0       0.001119            0.0   \n",
       "25595            0.000703                 0.0       0.000245            0.0   \n",
       "\n",
       "       Atelectasis_pred  Atelectasis_true  Emphysema_pred  Emphysema_true  \n",
       "0              0.126238               0.0        0.035488             0.0  \n",
       "1              0.024457               0.0        0.063976             0.0  \n",
       "2              0.250383               0.0        0.050591             0.0  \n",
       "3              0.084552               0.0        0.028125             0.0  \n",
       "4              0.153732               0.0        0.110478             0.0  \n",
       "...                 ...               ...             ...             ...  \n",
       "25591          0.002743               0.0        0.000820             0.0  \n",
       "25592          0.004384               0.0        0.004066             0.0  \n",
       "25593          0.001059               0.0        0.001289             0.0  \n",
       "25594          0.001156               0.0        0.000957             0.0  \n",
       "25595          0.000871               0.0        0.000894             0.0  \n",
       "\n",
       "[25596 rows x 33 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_clip = pd.read_csv(\"../../results/nih/clip-linear-bce-1e-5/test_predictions.csv\", sep=\",\")\n",
    "results_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25596, 33)\n",
      "\n",
      "Macro AUC-ROC scores by sex:\n",
      "         Macro AUC-ROC  Sample Size\n",
      "F                0.789      10714.0\n",
      "M                0.792      14882.0\n",
      "unknown            NaN          NaN\n",
      "\n",
      "Macro AUC-ROC scores by age bin:\n",
      "       Macro AUC-ROC  Sample Size\n",
      "18-35          0.736         6076\n",
      "36-50          0.796         6431\n",
      "51-70          0.784        10538\n",
      "71+            0.772         1481\n"
     ]
    }
   ],
   "source": [
    "# NIH\n",
    "\n",
    "\n",
    "results_clip = pd.read_csv(\"../../results/nih/clip-linear-bce-1e-5/test_predictions.csv\", sep=\",\")\n",
    "print(results_clip.shape)\n",
    "# Merge the results with admissions data\n",
    "\n",
    "# Convert age to numeric, coercing errors to NaN\n",
    "results_clip['age'] = pd.to_numeric(results_clip['age'], errors='coerce')\n",
    "\n",
    "\n",
    "# Calculate for sex\n",
    "sexes = ['M', 'F', 'unknown']\n",
    "sex_results = calculate_group_metrics(results_clip, 'sex', sexes)\n",
    "\n",
    "# Create age bins with new ranges\n",
    "results_clip['age_bin'] = pd.cut(results_clip['age'], \n",
    "                                bins=[17, 35, 50, 70, 100],\n",
    "                                labels=['18-35', '36-50', '51-70', '71+'])\n",
    "age_results = calculate_group_metrics(results_clip, 'age_bin', \n",
    "                                    results_clip['age_bin'].dropna().unique())\n",
    "\n",
    "\n",
    "print(\"\\nMacro AUC-ROC scores by sex:\")\n",
    "print(sex_results)\n",
    "print(\"\\nMacro AUC-ROC scores by age bin:\")\n",
    "print(age_results.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25596, 33)\n",
      "\n",
      "Macro AUC-ROC scores by sex:\n",
      "         Macro AUC-ROC  Sample Size\n",
      "F                0.789      10714.0\n",
      "M                0.782      14882.0\n",
      "unknown            NaN          NaN\n",
      "\n",
      "Macro AUC-ROC scores by age bin:\n",
      "       Macro AUC-ROC  Sample Size\n",
      "18-35          0.739         6076\n",
      "36-50          0.795         6431\n",
      "51-70          0.774        10538\n",
      "71+            0.760         1481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_dino = pd.read_csv(\"../../results/nih/dino-linear-bce-1e-5/test_predictions.csv\", sep=\",\")\n",
    "print(results_dino.shape)\n",
    "# Merge the results with admissions data\n",
    "\n",
    "# Convert age to numeric, coercing errors to NaN\n",
    "results_dino['age'] = pd.to_numeric(results_dino['age'], errors='coerce')\n",
    "\n",
    "\n",
    "# Calculate for sex\n",
    "sexes = ['M', 'F', 'unknown']\n",
    "sex_results = calculate_group_metrics(results_dino, 'sex', sexes)\n",
    "\n",
    "# Create age bins with new ranges\n",
    "results_dino['age_bin'] = pd.cut(results_dino['age'], \n",
    "                                bins=[17, 35, 50, 70, 100],\n",
    "                                labels=['18-35', '36-50', '51-70', '71+'])\n",
    "age_results = calculate_group_metrics(results_dino, 'age_bin', \n",
    "                                    results_dino['age_bin'].dropna().unique())\n",
    "\n",
    "\n",
    "print(\"\\nMacro AUC-ROC scores by sex:\")\n",
    "print(sex_results)\n",
    "print(\"\\nMacro AUC-ROC scores by age bin:\")\n",
    "print(age_results.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
